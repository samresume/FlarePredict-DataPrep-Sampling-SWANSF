{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b42f5d50",
   "metadata": {},
   "source": [
    "# SVM - MLPClassifier - Gaussian Naive Bayes  - Randon Forest on NewFeatures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5d323d1",
   "metadata": {},
   "source": [
    "# Train Test Split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d29e199",
   "metadata": {},
   "source": [
    "## Stratified Cross validation (k = 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c37f292",
   "metadata": {},
   "source": [
    "P1 Train and P2 Test, P1 Train and P3 Test, P1 Train and P4 Test, P1 Train and P5 Test\n",
    "P2 Train and P3 Test, P2 Train and P4 Test, P2 Train and P5 Test\n",
    "P3 Train and P4 Test, P3 Train and P5 Test\n",
    "P4 Train and P5 Test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "529fa14d",
   "metadata": {},
   "source": [
    "# Evaluation Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "255d0498",
   "metadata": {},
   "outputs": [],
   "source": [
    "# float(\"{:.2f}\".format(13.949999999999999))\n",
    "\n",
    "def TSS(TP,TN,FP,FN):\n",
    "    TSS_value = (TP / (TP + FN)) - (FP / (FP + TN))\n",
    "    return TSS_value\n",
    "\n",
    "def HSS1(TP,TN,FP,FN):\n",
    "    HSS1_value = (2 * (TP * TN - FP * FN)) / ((TP + FN) * (FN + TN) + (TP + FP) * (FP + TN))\n",
    "    return HSS1_value\n",
    "    \n",
    "def HSS2(TP,TN,FP,FN):\n",
    "    HSS2_value = (2 * (TP * TN - FP * FN)) / ((TP + FP) * (FN + TN) + (TP + FN) * (FP + TN))\n",
    "    return HSS2_value\n",
    "\n",
    "def GSS(TP,TN,FP,FN):\n",
    "    GSS_value = (TP - (TP + FP) * (TP + FN) / (TP + FP + FN + TN))\n",
    "    return GSS_value\n",
    "\n",
    "def Recall(TP,TN,FP,FN):\n",
    "    Recall_value = (TP) / (TP + FN)\n",
    "    return Recall_value\n",
    "\n",
    "def FPR(TP,TN,FP,FN):\n",
    "    fpr_value = (FP) / (FP + TN)\n",
    "    return fpr_value\n",
    "\n",
    "def Accuracy(TP,TN,FP,FN):\n",
    "    accuracy_value = (TP + TN) / (TP + TN + FP + FN)\n",
    "    return accuracy_value\n",
    "\n",
    "def Precision(TP,TN,FP,FN):\n",
    "    precision_value = (FP) / (TP + FP)\n",
    "    return precision_value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd0d872d",
   "metadata": {},
   "source": [
    "# Loading the Final Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9516c63",
   "metadata": {},
   "source": [
    "## New Features "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "534e436f",
   "metadata": {},
   "source": [
    "### LSBZM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ebdc0e3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P1 Nan-Value: False\n",
      "P2 Nan-Value: False\n",
      "P3 Nan-Value: False\n",
      "P4 Nan-Value: False\n",
      "P5 Nan-Value: False\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "data_dir = \"/Users/samskanderi/Documents/Research_Project/SWANSF/code/5_2_FinalData_NewFeatures_LSBZM_KnnImputation/\"\n",
    "X_train_NewF_LSBZM = []\n",
    "Y_train_NewF_LSBZM = []\n",
    "\n",
    "\n",
    "num_partitions = 5\n",
    "\n",
    "for i in range(0,num_partitions):\n",
    "    with open(data_dir + \"Partition\" + str(i+1) + \"_NewFeatures_LSBZM_KnnImputation\" + \".pkl\", 'rb') as f:\n",
    "        X_train_NewF_LSBZM.append(pickle.load(f))\n",
    "    print(\"P\"+str(i+1)+\" Nan-Value: \"+ str(np.isnan(X_train_NewF_LSBZM[i]).any() or np.isinf(X_train_NewF_LSBZM[i]).any()))\n",
    "    \n",
    "    with open(data_dir + \"Partition\" + str(i+1) + \"_Labels_NewFeatures_LSBZM_KnnImputation\" + \".pkl\", 'rb') as f:\n",
    "        Y_train_NewF_LSBZM.append(pickle.load(f))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d520699a",
   "metadata": {},
   "source": [
    "# Useful Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ed6ceb4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kfold_training(name, X_train, Y_train, training_func, num, rocket_kernels= 1500, tsf_estimator=25):\n",
    "    kfold = np.array([[1,2],[1,3],[1,4],[1,5],[2,3],[2,4],[2,5],[3,4],[3,5],[4,5]])\n",
    "    metrics = []\n",
    "    metrics_values = np.array([])\n",
    "    \n",
    "    for i in range(0, num):\n",
    "        train_index = kfold[i,0]\n",
    "        test_index = kfold[i,1]\n",
    "        metrics_values = training_func(X_train[train_index-1], Y_train[train_index-1], X_train[test_index-1], Y_train[test_index-1])\n",
    "        while (metrics_values[0] == 0):\n",
    "            metrics_values = training_func(X_train[train_index-1], Y_train[train_index-1], X_train[test_index-1], Y_train[test_index-1])\n",
    "        \n",
    "        metrics.append(np.append(np.append(train_index, test_index), metrics_values))\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faf5130c",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10454d6f",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9a1291ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def svm_model(X_train, Y_train, X_test, Y_test):\n",
    "    \n",
    "    data_dir = \"/Users/samskanderi/Documents/Research_Project/SWANSF/code/models/\"\n",
    "\n",
    "\n",
    "    # Create an SVM classifier (you can choose different kernels like 'linear', 'rbf', etc.)\n",
    "    svm_classifier = SVC(kernel='rbf', C=1.0)\n",
    "    svm_classifier.fit(X_train, Y_train)\n",
    "    y_pred = svm_classifier.predict(X_test)\n",
    "    \n",
    "    \n",
    "    print(str(X_train.shape)+': SVM Classifier is Done! \\n')\n",
    "    \n",
    "\n",
    "    confusion = confusion_matrix(Y_test, y_pred)\n",
    "    tn, fp, fn, tp = confusion.ravel()\n",
    "\n",
    "    tss = TSS(tp,tn,fp,fn)\n",
    "    hss1 = HSS1(tp,tn,fp,fn)\n",
    "    hss2 = HSS2(tp,tn,fp,fn)\n",
    "    gss = GSS(tp,tn,fp,fn)\n",
    "    recall = Recall(tp,tn,fp,fn)\n",
    "    precision = Precision(tp,tn,fp,fn)\n",
    "    \n",
    "    output_values = np.array([tp, fn, fp, tn, tss, hss1, hss2, gss, recall, precision])\n",
    "\n",
    "\n",
    "    #joblib.dump(classifier, data_dir + \"svm_model.pkl\")\n",
    "\n",
    "    #loaded_svm_model = joblib.load(data_dir + \"svm_model.pkl\")\n",
    "    \n",
    "    return output_values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12a9a3ae",
   "metadata": {},
   "source": [
    "## MPLClassifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a780f706",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def mlp_model(X_train, Y_train, X_test, Y_test):\n",
    "    \n",
    "    data_dir = \"/Users/samskanderi/Documents/Research_Project/SWANSF/code/models/\"\n",
    "\n",
    "    # Define the MLP model\n",
    "    # Define the MLP model with four hidden layers\n",
    "    model = keras.Sequential([\n",
    "        layers.Input(shape=(216,)),  # Input layer with 216 features\n",
    "        layers.Dense(64, activation='relu'),  # Hidden layer with 64 units and ReLU activation\n",
    "        layers.Dense(32, activation='relu'),  # Hidden layer with 32 units and ReLU activation\n",
    "        layers.Dense(16, activation='relu'),  # Hidden layer with 16 units and ReLU activation\n",
    "        layers.Dense(8, activation='relu'),  # Hidden layer with 16 units and ReLU activation\n",
    "        layers.Dense(1, activation='sigmoid')  # Output layer with 1 unit and sigmoid activation (binary classification)\n",
    "    ])\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=keras.metrics.Recall(name='recall'))\n",
    "\n",
    "    # Train the model\n",
    "    model.fit(X_train, Y_train, epochs=15, batch_size=32, verbose=0)  # Adjust epochs and batch_size as needed\n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "    threshold = 0.35  # Adjust the threshold as needed\n",
    "    y_pred_binary = (y_pred > threshold).astype(int)\n",
    "    \n",
    "    print(str(X_train.shape)+': MLP Classifier is Done! \\n')\n",
    "\n",
    "\n",
    "    confusion = confusion_matrix(Y_test, y_pred_binary)\n",
    "    tn, fp, fn, tp = confusion.ravel()\n",
    "\n",
    "    tss = TSS(tp,tn,fp,fn)\n",
    "    hss1 = HSS1(tp,tn,fp,fn)\n",
    "    hss2 = HSS2(tp,tn,fp,fn)\n",
    "    gss = GSS(tp,tn,fp,fn)\n",
    "    recall = Recall(tp,tn,fp,fn)\n",
    "    precision = Precision(tp,tn,fp,fn)\n",
    "    \n",
    "    output_values = np.array([tp, fn, fp, tn, tss, hss1, hss2, gss, recall, precision])\n",
    "\n",
    "\n",
    "    #joblib.dump(classifier, data_dir + \"mlp_model.pkl\")\n",
    "\n",
    "    #loaded_mlp_model = joblib.load(data_dir + \"mlp_model.pkl\")\n",
    "    \n",
    "    return output_values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d6b8014",
   "metadata": {},
   "source": [
    "# Complement Naive Bayes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "994a30d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.naive_bayes import ComplementNB\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def naive_bayes_model(X_train, Y_train, X_test, Y_test):\n",
    "    \n",
    "    data_dir = \"/Users/samskanderi/Documents/Research_Project/SWANSF/code/models/\"\n",
    "\n",
    "    # Create a Gaussian Naive Bayes classifier\n",
    "    nb_classifier = ComplementNB(force_alpha=True)\n",
    "    nb_classifier.fit(X_train, Y_train)\n",
    "    y_pred = nb_classifier.predict(X_test)\n",
    "    \n",
    "    print(str(X_train.shape) + ': Naive Bayes Classifier is Done! \\n')\n",
    "\n",
    "    confusion = confusion_matrix(Y_test, y_pred)\n",
    "    tn, fp, fn, tp = confusion.ravel()\n",
    "\n",
    "    tss = TSS(tp,tn,fp,fn)\n",
    "    hss1 = HSS1(tp,tn,fp,fn)\n",
    "    hss2 = HSS2(tp,tn,fp,fn)\n",
    "    gss = GSS(tp,tn,fp,fn)\n",
    "    recall = Recall(tp,tn,fp,fn)\n",
    "    precision = Precision(tp,tn,fp,fn)\n",
    "    \n",
    "    output_values = np.array([tp, fn, fp, tn, tss, hss1, hss2, gss, recall, precision])\n",
    "\n",
    "    #joblib.dump(nb_classifier, data_dir + \"naive_bayes_model.pkl\")\n",
    "\n",
    "    #loaded_nb_model = joblib.load(data_dir + \"naive_bayes_model.pkl\")\n",
    "\n",
    "    return output_values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cec60e3",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "55986975",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def random_forest_model(X_train, Y_train, X_test, Y_test):\n",
    "    \n",
    "    data_dir = \"/Users/samskanderi/Documents/Research_Project/SWANSF/code/models/\"\n",
    "\n",
    "    # Create a Random Forest classifier\n",
    "    # You can adjust 'n_estimators' and other parameters as needed\n",
    "    rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    rf_classifier.fit(X_train, Y_train)\n",
    "    y_pred = rf_classifier.predict(X_test)\n",
    "    \n",
    "    print(str(X_train.shape) + ': Random Forest Classifier is Done! \\n')\n",
    "\n",
    "    confusion = confusion_matrix(Y_test, y_pred)\n",
    "    tn, fp, fn, tp = confusion.ravel()\n",
    "\n",
    "    tss = TSS(tp, tn, fp, fn)\n",
    "    hss1 = HSS1(tp, tn, fp, fn)\n",
    "    hss2 = HSS2(tp, tn, fp, fn)\n",
    "    gss = GSS(tp, tn, fp, fn)\n",
    "    recall = Recall(tp, tn, fp, fn)\n",
    "    precision = Precision(tp, tn, fp, fn)\n",
    "    \n",
    "    output_values = np.array([tp, fn, fp, tn, tss, hss1, hss2, gss, recall, precision])\n",
    "\n",
    "    #joblib.dump(rf_classifier, data_dir + \"random_forest_model.pkl\")\n",
    "\n",
    "    #loaded_rf_model = joblib.load(data_dir + \"random_forest_model.pkl\")\n",
    "\n",
    "    return output_values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32e9fd1e",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "127986e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_results(reslut, name):\n",
    "    data_dir = \"/Users/samskanderi/Documents/Research_Project/SWANSF/code/results/\"\n",
    "\n",
    "    with open(data_dir + name + \".pkl\", 'wb') as f:\n",
    "        pickle.dump(reslut, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c7bc689",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5b280418",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(73492, 216): SVM Classifier is Done! \n",
      "\n",
      "(73492, 216): SVM Classifier is Done! \n",
      "\n",
      "(73492, 216): SVM Classifier is Done! \n",
      "\n",
      "(73492, 216): SVM Classifier is Done! \n",
      "\n",
      "(88557, 216): SVM Classifier is Done! \n",
      "\n",
      "(88557, 216): SVM Classifier is Done! \n",
      "\n",
      "(88557, 216): SVM Classifier is Done! \n",
      "\n",
      "(42510, 216): SVM Classifier is Done! \n",
      "\n",
      "(42510, 216): SVM Classifier is Done! \n",
      "\n",
      "(51261, 216): SVM Classifier is Done! \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# SVM NewFeatures\n",
    "svm_newf = kfold_training('SVM', X_train_NewF_LSBZM, Y_train_NewF_LSBZM, svm_model, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a14a0c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_results(svm_newf, \"SVM_NewFeatures_Results\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5ce17de",
   "metadata": {},
   "source": [
    "## MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4dd95319",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2768/2768 [==============================] - 1s 223us/step\n",
      "(73492, 216): MLP Classifier is Done! \n",
      "\n",
      "1329/1329 [==============================] - 0s 230us/step\n",
      "(73492, 216): MLP Classifier is Done! \n",
      "\n",
      "1602/1602 [==============================] - 0s 227us/step\n",
      "(73492, 216): MLP Classifier is Done! \n",
      "\n",
      "2356/2356 [==============================] - 1s 232us/step\n",
      "(73492, 216): MLP Classifier is Done! \n",
      "\n",
      "1329/1329 [==============================] - 0s 227us/step\n",
      "(88557, 216): MLP Classifier is Done! \n",
      "\n",
      "1602/1602 [==============================] - 0s 226us/step\n",
      "(88557, 216): MLP Classifier is Done! \n",
      "\n",
      "2356/2356 [==============================] - 1s 226us/step\n",
      "(88557, 216): MLP Classifier is Done! \n",
      "\n",
      "2356/2356 [==============================] - 1s 226us/step\n",
      "(88557, 216): MLP Classifier is Done! \n",
      "\n",
      "1602/1602 [==============================] - 0s 225us/step\n",
      "(42510, 216): MLP Classifier is Done! \n",
      "\n",
      "2356/2356 [==============================] - 1s 226us/step\n",
      "(42510, 216): MLP Classifier is Done! \n",
      "\n",
      "2356/2356 [==============================] - 1s 227us/step\n",
      "(51261, 216): MLP Classifier is Done! \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# MLPClassifier NewFeatures\n",
    "mlp_newf = kfold_training('MLP', X_train_NewF_LSBZM, Y_train_NewF_LSBZM, mlp_model, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "097d194e",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_results(mlp_newf, \"MLPClassifier_NewFeatures_Results\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e702be07",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b24408d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(73492, 216): Naive Bayes Classifier is Done! \n",
      "\n",
      "(73492, 216): Naive Bayes Classifier is Done! \n",
      "\n",
      "(73492, 216): Naive Bayes Classifier is Done! \n",
      "\n",
      "(73492, 216): Naive Bayes Classifier is Done! \n",
      "\n",
      "(88557, 216): Naive Bayes Classifier is Done! \n",
      "\n",
      "(88557, 216): Naive Bayes Classifier is Done! \n",
      "\n",
      "(88557, 216): Naive Bayes Classifier is Done! \n",
      "\n",
      "(42510, 216): Naive Bayes Classifier is Done! \n",
      "\n",
      "(42510, 216): Naive Bayes Classifier is Done! \n",
      "\n",
      "(51261, 216): Naive Bayes Classifier is Done! \n",
      "\n"
     ]
    }
   ],
   "source": [
    "naive_newf = kfold_training('NaiveBayes', X_train_NewF_LSBZM, Y_train_NewF_LSBZM, naive_bayes_model, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6ac1c1a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_results(naive_newf, \"NaiveBayes_NewFeatures_Results\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c43112c",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fc2f461e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(73492, 216): Random Forest Classifier is Done! \n",
      "\n",
      "(73492, 216): Random Forest Classifier is Done! \n",
      "\n",
      "(73492, 216): Random Forest Classifier is Done! \n",
      "\n",
      "(73492, 216): Random Forest Classifier is Done! \n",
      "\n",
      "(88557, 216): Random Forest Classifier is Done! \n",
      "\n",
      "(88557, 216): Random Forest Classifier is Done! \n",
      "\n",
      "(88557, 216): Random Forest Classifier is Done! \n",
      "\n",
      "(42510, 216): Random Forest Classifier is Done! \n",
      "\n",
      "(42510, 216): Random Forest Classifier is Done! \n",
      "\n",
      "(51261, 216): Random Forest Classifier is Done! \n",
      "\n"
     ]
    }
   ],
   "source": [
    "forest_newf = kfold_training('RandomForest', X_train_NewF_LSBZM, Y_train_NewF_LSBZM, random_forest_model, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5b25573a",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_results(forest_newf, \"RandomForest_NewFeatures_Results\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0fc66c6",
   "metadata": {},
   "source": [
    "# Comparison "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3941d553",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"/Users/samskanderi/Documents/Research_Project/SWANSF/code/results/\"\n",
    "with open(data_dir + 'SVM_NewFeatures_Results' + \".pkl\", 'rb') as f:\n",
    "    svm_newf=pickle.load(f)\n",
    "with open(data_dir + 'MLPClassifier_NewFeatures_Results' + \".pkl\", 'rb') as f:\n",
    "    mlp_newf=pickle.load(f)\n",
    "with open(data_dir + 'NaiveBayes_NewFeatures_Results' + \".pkl\", 'rb') as f:\n",
    "    naive_newf=pickle.load(f)\n",
    "with open(data_dir + 'RandomForest_NewFeatures_Results' + \".pkl\", 'rb') as f:\n",
    "    forest_newf=pickle.load(f)\n",
    "\n",
    "\n",
    "\n",
    "names = ['SVM', 'MLP', 'NaiveBayes', 'RandomForest']\n",
    "values = np.array([svm_newf, mlp_newf, naive_newf, forest_newf])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "88522bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_results(names, values):\n",
    "    np.printoptions(precision=4, suppress=True)\n",
    "    for i in range(0, values.shape[1]):\n",
    "        print(\"P_Train = \"+ str(values[0,i,0]) + \" & \" + \"P_Test = \" + str(values[0,i,1]))\n",
    "        for j in range(0, values.shape[0]):\n",
    "            print(names[j] + ' :' +  ' TP={:.0f}'.format(values[j,i,2]) + ' FN={:.0f}'.format(values[j,i,3]) + ' FP={:.0f}'.format(values[j,i,4])\n",
    "                 + ' TN={:.0f}'.format(values[j,i,5]) + ' TSS={:.3f}'.format(values[j,i,6]) + ' HSS1={:.3f}'.format(values[j,i,7]) + ' HSS2={:.3f}'.format(values[j,i,8])\n",
    "                 + ' GSS={:.3f}'.format(values[j,i,9]) + ' Recall={:.3f}'.format(values[j,i,10]) + ' Precision={:.3f}'.format(values[j,i,11]))\n",
    "        print('\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9688f338",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P_Train = 1.0 & P_Test = 2.0\n",
      "SVM : TP=100 FN=1301 FP=79 TN=87077 TSS=0.070 HSS1=0.123 HSS2=0.125 GSS=97.168 Recall=0.071 Precision=0.441\n",
      "MLP : TP=573 FN=828 FP=719 TN=86437 TSS=0.401 HSS1=0.417 HSS2=0.417 GSS=552.560 Recall=0.409 Precision=0.557\n",
      "NaiveBayes : TP=1334 FN=67 FP=18509 TN=68647 TSS=0.740 HSS1=0.099 HSS2=0.122 GSS=1020.077 Recall=0.952 Precision=0.933\n",
      "RandomForest : TP=224 FN=1177 FP=199 TN=86957 TSS=0.158 HSS1=0.240 HSS2=0.241 GSS=217.308 Recall=0.160 Precision=0.470\n",
      "\n",
      "\n",
      "P_Train = 1.0 & P_Test = 3.0\n",
      "SVM : TP=80 FN=1344 FP=17 TN=41069 TSS=0.056 HSS1=0.101 HSS2=0.104 GSS=76.751 Recall=0.056 Precision=0.175\n",
      "MLP : TP=583 FN=841 FP=671 TN=40415 TSS=0.393 HSS1=0.417 HSS2=0.417 GSS=540.994 Recall=0.409 Precision=0.535\n",
      "NaiveBayes : TP=1345 FN=79 FP=7685 TN=33401 TSS=0.757 HSS1=0.212 HSS2=0.246 GSS=1042.513 Recall=0.945 Precision=0.851\n",
      "RandomForest : TP=73 FN=1351 FP=112 TN=40974 TSS=0.049 HSS1=0.084 HSS2=0.086 GSS=66.803 Recall=0.051 Precision=0.605\n",
      "\n",
      "\n",
      "P_Train = 1.0 & P_Test = 4.0\n",
      "SVM : TP=106 FN=1059 FP=6 TN=50090 TSS=0.091 HSS1=0.163 HSS2=0.165 GSS=103.455 Recall=0.091 Precision=0.054\n",
      "MLP : TP=482 FN=683 FP=281 TN=49815 TSS=0.408 HSS1=0.491 HSS2=0.492 GSS=464.659 Recall=0.414 Precision=0.368\n",
      "NaiveBayes : TP=1124 FN=41 FP=8941 TN=41155 TSS=0.786 HSS1=0.166 HSS2=0.194 GSS=895.254 Recall=0.965 Precision=0.888\n",
      "RandomForest : TP=220 FN=945 FP=82 TN=50014 TSS=0.187 HSS1=0.293 HSS2=0.296 GSS=213.136 Recall=0.189 Precision=0.272\n",
      "\n",
      "\n",
      "P_Train = 1.0 & P_Test = 5.0\n",
      "SVM : TP=9 FN=981 FP=111 TN=74264 TSS=0.008 HSS1=0.013 HSS2=0.014 GSS=7.424 Recall=0.009 Precision=0.925\n",
      "MLP : TP=753 FN=237 FP=1988 TN=72387 TSS=0.734 HSS1=0.392 HSS2=0.396 GSS=716.994 Recall=0.761 Precision=0.725\n",
      "NaiveBayes : TP=987 FN=3 FP=16582 TN=57793 TSS=0.774 HSS1=0.084 HSS2=0.105 GSS=756.212 Recall=0.997 Precision=0.944\n",
      "RandomForest : TP=327 FN=663 FP=346 TN=74029 TSS=0.326 HSS1=0.387 HSS2=0.387 GSS=318.159 Recall=0.330 Precision=0.514\n",
      "\n",
      "\n",
      "P_Train = 2.0 & P_Test = 3.0\n",
      "SVM : TP=170 FN=1254 FP=33 TN=41053 TSS=0.119 HSS1=0.202 HSS2=0.207 GSS=163.200 Recall=0.119 Precision=0.163\n",
      "MLP : TP=797 FN=627 FP=1436 TN=39650 TSS=0.525 HSS1=0.412 HSS2=0.414 GSS=722.199 Recall=0.560 Precision=0.643\n",
      "NaiveBayes : TP=1405 FN=19 FP=8885 TN=32201 TSS=0.770 HSS1=0.192 HSS2=0.231 GSS=1060.306 Recall=0.987 Precision=0.863\n",
      "RandomForest : TP=186 FN=1238 FP=184 TN=40902 TSS=0.126 HSS1=0.196 HSS2=0.199 GSS=173.606 Recall=0.131 Precision=0.497\n",
      "\n",
      "\n",
      "P_Train = 2.0 & P_Test = 4.0\n",
      "SVM : TP=63 FN=1102 FP=0 TN=50096 TSS=0.054 HSS1=0.101 HSS2=0.102 GSS=61.568 Recall=0.054 Precision=0.000\n",
      "MLP : TP=185 FN=980 FP=55 TN=50041 TSS=0.158 HSS1=0.258 HSS2=0.261 GSS=179.546 Recall=0.159 Precision=0.229\n",
      "NaiveBayes : TP=1130 FN=35 FP=9982 TN=40114 TSS=0.771 HSS1=0.149 HSS2=0.178 GSS=877.459 Recall=0.970 Precision=0.898\n",
      "RandomForest : TP=108 FN=1057 FP=15 TN=50081 TSS=0.092 HSS1=0.164 HSS2=0.167 GSS=105.205 Recall=0.093 Precision=0.122\n",
      "\n",
      "\n",
      "P_Train = 2.0 & P_Test = 5.0\n",
      "SVM : TP=214 FN=776 FP=71 TN=74304 TSS=0.215 HSS1=0.332 HSS2=0.333 GSS=210.256 Recall=0.216 Precision=0.249\n",
      "MLP : TP=439 FN=551 FP=702 TN=73673 TSS=0.434 HSS1=0.404 HSS2=0.404 GSS=424.012 Recall=0.443 Precision=0.615\n",
      "NaiveBayes : TP=988 FN=2 FP=19223 TN=55152 TSS=0.740 HSS1=0.070 HSS2=0.092 GSS=722.507 Recall=0.998 Precision=0.951\n",
      "RandomForest : TP=135 FN=855 FP=374 TN=74001 TSS=0.131 HSS1=0.173 HSS2=0.173 GSS=128.314 Recall=0.136 Precision=0.735\n",
      "\n",
      "\n",
      "P_Train = 3.0 & P_Test = 4.0\n",
      "SVM : TP=119 FN=1046 FP=1 TN=50095 TSS=0.102 HSS1=0.182 HSS2=0.185 GSS=116.273 Recall=0.102 Precision=0.008\n",
      "MLP : TP=217 FN=948 FP=59 TN=50037 TSS=0.185 HSS1=0.295 HSS2=0.298 GSS=210.727 Recall=0.186 Precision=0.214\n",
      "NaiveBayes : TP=1164 FN=1 FP=13642 TN=36454 TSS=0.727 HSS1=0.108 HSS2=0.142 GSS=827.507 Recall=0.999 Precision=0.921\n",
      "RandomForest : TP=186 FN=979 FP=106 TN=49990 TSS=0.158 HSS1=0.248 HSS2=0.251 GSS=179.364 Recall=0.160 Precision=0.363\n",
      "\n",
      "\n",
      "P_Train = 3.0 & P_Test = 5.0\n",
      "SVM : TP=384 FN=606 FP=424 TN=73951 TSS=0.382 HSS1=0.420 HSS2=0.420 GSS=373.386 Recall=0.388 Precision=0.525\n",
      "MLP : TP=849 FN=141 FP=3167 TN=71208 TSS=0.815 HSS1=0.325 HSS2=0.333 GSS=796.246 Recall=0.858 Precision=0.789\n",
      "NaiveBayes : TP=990 FN=0 FP=26136 TN=48239 TSS=0.649 HSS1=0.046 HSS2=0.069 GSS=633.671 Recall=1.000 Precision=0.964\n",
      "RandomForest : TP=306 FN=684 FP=538 TN=73837 TSS=0.302 HSS1=0.326 HSS2=0.326 GSS=294.913 Recall=0.309 Precision=0.637\n",
      "\n",
      "\n",
      "P_Train = 4.0 & P_Test = 5.0\n",
      "SVM : TP=751 FN=239 FP=2216 TN=72159 TSS=0.729 HSS1=0.367 HSS2=0.372 GSS=712.025 Recall=0.759 Precision=0.747\n",
      "MLP : TP=775 FN=215 FP=3098 TN=71277 TSS=0.741 HSS1=0.304 HSS2=0.311 GSS=724.124 Recall=0.783 Precision=0.800\n",
      "NaiveBayes : TP=988 FN=2 FP=19984 TN=54391 TSS=0.729 HSS1=0.067 HSS2=0.088 GSS=712.510 Recall=0.998 Precision=0.953\n",
      "RandomForest : TP=511 FN=479 FP=2364 TN=72011 TSS=0.484 HSS1=0.250 HSS2=0.253 GSS=473.234 Recall=0.516 Precision=0.822\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "compare_results(names, values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db226f87",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7d2449b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
