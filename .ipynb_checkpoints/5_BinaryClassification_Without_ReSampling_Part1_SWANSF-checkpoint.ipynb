{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b42f5d50",
   "metadata": {},
   "source": [
    "# SVM - MLPClassifier on NewFeatures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5d323d1",
   "metadata": {},
   "source": [
    "# Train Test Split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d29e199",
   "metadata": {},
   "source": [
    "## Stratified Cross validation (k = 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c37f292",
   "metadata": {},
   "source": [
    "P1 Train and P2 Test, P1 Train and P3 Test, P1 Train and P4 Test, P1 Train and P5 Test\n",
    "P2 Train and P3 Test, P2 Train and P4 Test, P2 Train and P5 Test\n",
    "P3 Train and P4 Test, P3 Train and P5 Test\n",
    "P4 Train and P5 Test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "529fa14d",
   "metadata": {},
   "source": [
    "# Evaluation Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "255d0498",
   "metadata": {},
   "outputs": [],
   "source": [
    "# float(\"{:.2f}\".format(13.949999999999999))\n",
    "\n",
    "def TSS(TP,TN,FP,FN):\n",
    "    TSS_value = (TP / (TP + FN)) - (FP / (FP + TN))\n",
    "    return TSS_value\n",
    "\n",
    "def HSS1(TP,TN,FP,FN):\n",
    "    HSS1_value = (2 * (TP * TN - FP * FN)) / ((TP + FN) * (FN + TN) + (TP + FP) * (FP + TN))\n",
    "    return HSS1_value\n",
    "    \n",
    "def HSS2(TP,TN,FP,FN):\n",
    "    HSS2_value = (2 * (TP * TN - FP * FN)) / ((TP + FP) * (FN + TN) + (TP + FN) * (FP + TN))\n",
    "    return HSS2_value\n",
    "\n",
    "def GSS(TP,TN,FP,FN):\n",
    "    GSS_value = (TP - (TP + FP) * (TP + FN) / (TP + FP + FN + TN))\n",
    "    return GSS_value\n",
    "\n",
    "def Recall(TP,TN,FP,FN):\n",
    "    Recall_value = (TP) / (TP + FN)\n",
    "    return Recall_value\n",
    "\n",
    "def FPR(TP,TN,FP,FN):\n",
    "    fpr_value = (FP) / (FP + TN)\n",
    "    return fpr_value\n",
    "\n",
    "def Accuracy(TP,TN,FP,FN):\n",
    "    accuracy_value = (TP + TN) / (TP + TN + FP + FN)\n",
    "    return accuracy_value\n",
    "\n",
    "def Precision(TP,TN,FP,FN):\n",
    "    precision_value = (FP) / (TP + FP)\n",
    "    return precision_value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd0d872d",
   "metadata": {},
   "source": [
    "# Loading the Final Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9516c63",
   "metadata": {},
   "source": [
    "## New Features "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aca76aee",
   "metadata": {},
   "source": [
    "### ZM Norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "06c2f0ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P1 Nan-Value: False\n",
      "P2 Nan-Value: False\n",
      "P3 Nan-Value: False\n",
      "P4 Nan-Value: False\n",
      "P5 Nan-Value: False\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "data_dir = \"/Users/samskanderi/Documents/Research_Project/SWANSF/code/5_1_FinalData_NewFeatures_ZM_KnnImputation/\"\n",
    "X_train_NewF_ZM = []\n",
    "Y_train_NewF_ZM = []\n",
    "\n",
    "\n",
    "num_partitions = 5\n",
    "\n",
    "for i in range(0,num_partitions):\n",
    "    with open(data_dir + \"Partition\" + str(i+1) + \"_NewFeatures_ZM_KnnImputation\" + \".pkl\", 'rb') as f:\n",
    "        X_train_NewF_ZM.append(pickle.load(f))\n",
    "    print(\"P\"+str(i+1)+\" Nan-Value: \"+ str(np.isnan(X_train_NewF_ZM[i]).any() or np.isinf(X_train_NewF_ZM[i]).any()))\n",
    "    \n",
    "    with open(data_dir + \"Partition\" + str(i+1) + \"_Labels_NewFeatures_ZM_KnnImputation\" + \".pkl\", 'rb') as f:\n",
    "        Y_train_NewF_ZM.append(pickle.load(f))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "534e436f",
   "metadata": {},
   "source": [
    "### LSBZM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ebdc0e3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P1 Nan-Value: False\n",
      "P2 Nan-Value: False\n",
      "P3 Nan-Value: False\n",
      "P4 Nan-Value: False\n",
      "P5 Nan-Value: False\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "data_dir = \"/Users/samskanderi/Documents/Research_Project/SWANSF/code/5_2_FinalData_NewFeatures_LSBZM_KnnImputation/\"\n",
    "X_train_NewF_LSBZM = []\n",
    "Y_train_NewF_LSBZM = []\n",
    "\n",
    "\n",
    "num_partitions = 5\n",
    "\n",
    "for i in range(0,num_partitions):\n",
    "    with open(data_dir + \"Partition\" + str(i+1) + \"_NewFeatures_LSBZM_KnnImputation\" + \".pkl\", 'rb') as f:\n",
    "        X_train_NewF_LSBZM.append(pickle.load(f))\n",
    "    print(\"P\"+str(i+1)+\" Nan-Value: \"+ str(np.isnan(X_train_NewF_LSBZM[i]).any() or np.isinf(X_train_NewF_LSBZM[i]).any()))\n",
    "    \n",
    "    with open(data_dir + \"Partition\" + str(i+1) + \"_Labels_NewFeatures_LSBZM_KnnImputation\" + \".pkl\", 'rb') as f:\n",
    "        Y_train_NewF_LSBZM.append(pickle.load(f))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d520699a",
   "metadata": {},
   "source": [
    "# Useful Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ed6ceb4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kfold_training(name, X_train, Y_train, training_func, num, rocket_kernels= 1500, tsf_estimator=25):\n",
    "    kfold = np.array([[1,2],[1,3],[1,4],[1,5],[2,3],[2,4],[2,5],[3,4],[3,5],[4,5]])\n",
    "    metrics = []\n",
    "    metrics_values = np.array([])\n",
    "    \n",
    "    for i in range(0, num):\n",
    "        train_index = kfold[i,0]\n",
    "        test_index = kfold[i,1]\n",
    "        metrics_values = training_func(X_train[train_index-1], Y_train[train_index-1], X_train[test_index-1], Y_train[test_index-1])\n",
    "\n",
    "        metrics.append(np.append(np.append(train_index, test_index), metrics_values))\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faf5130c",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10454d6f",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9a1291ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def svm_model(X_train, Y_train, X_test, Y_test):\n",
    "    \n",
    "    data_dir = \"/Users/samskanderi/Documents/Research_Project/SWANSF/code/models/\"\n",
    "\n",
    "\n",
    "    # Create an SVM classifier (you can choose different kernels like 'linear', 'rbf', etc.)\n",
    "    svm_classifier = SVC(kernel='linear', C=1.0)\n",
    "    svm_classifier.fit(X_train, Y_train)\n",
    "    y_pred = svm_classifier.predict(X_test)\n",
    "    \n",
    "    \n",
    "    print(str(X_train.shape)+': SVM Classifier is Done! \\n')\n",
    "    \n",
    "\n",
    "    confusion = confusion_matrix(Y_test, y_pred)\n",
    "    tn, fp, fn, tp = confusion.ravel()\n",
    "\n",
    "    tss = TSS(tp,tn,fp,fn)\n",
    "    hss1 = HSS1(tp,tn,fp,fn)\n",
    "    hss2 = HSS2(tp,tn,fp,fn)\n",
    "    gss = GSS(tp,tn,fp,fn)\n",
    "    recall = Recall(tp,tn,fp,fn)\n",
    "    precision = Precision(tp,tn,fp,fn)\n",
    "    \n",
    "    output_values = np.array([tp, fn, fp, tn, tss, hss1, hss2, gss, recall, precision])\n",
    "\n",
    "\n",
    "    #joblib.dump(classifier, data_dir + \"svm_model.pkl\")\n",
    "\n",
    "    #loaded_svm_model = joblib.load(data_dir + \"svm_model.pkl\")\n",
    "    \n",
    "    return output_values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12a9a3ae",
   "metadata": {},
   "source": [
    "## MPLClassifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a780f706",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def mlp_model(X_train, Y_train, X_test, Y_test):\n",
    "    \n",
    "    data_dir = \"/Users/samskanderi/Documents/Research_Project/SWANSF/code/models/\"\n",
    "\n",
    "    # Define the MLP model\n",
    "    # Define the MLP model with four hidden layers\n",
    "    model = keras.Sequential([\n",
    "        layers.Input(shape=(216,)),  # Input layer with 216 features\n",
    "        layers.Dense(64, activation='relu'),  # Hidden layer with 64 units and ReLU activation\n",
    "        layers.Dense(32, activation='relu'),  # Hidden layer with 32 units and ReLU activation\n",
    "        layers.Dense(16, activation='relu'),  # Hidden layer with 16 units and ReLU activation\n",
    "        layers.Dense(8, activation='relu'),  # Hidden layer with 16 units and ReLU activation\n",
    "        layers.Dense(1, activation='sigmoid')  # Output layer with 1 unit and sigmoid activation (binary classification)\n",
    "    ])\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=keras.metrics.Recall(name='recall'))\n",
    "\n",
    "    # Train the model\n",
    "    model.fit(X_train, Y_train, epochs=15, batch_size=32, verbose=0)  # Adjust epochs and batch_size as needed\n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "    threshold = 0.35  # Adjust the threshold as needed\n",
    "    y_pred_binary = (y_pred > threshold).astype(int)\n",
    "    \n",
    "    print(str(X_train.shape)+': MLP Classifier is Done! \\n')\n",
    "\n",
    "\n",
    "    confusion = confusion_matrix(Y_test, y_pred_binary)\n",
    "    tn, fp, fn, tp = confusion.ravel()\n",
    "\n",
    "    tss = TSS(tp,tn,fp,fn)\n",
    "    hss1 = HSS1(tp,tn,fp,fn)\n",
    "    hss2 = HSS2(tp,tn,fp,fn)\n",
    "    gss = GSS(tp,tn,fp,fn)\n",
    "    recall = Recall(tp,tn,fp,fn)\n",
    "    precision = Precision(tp,tn,fp,fn)\n",
    "    \n",
    "    output_values = np.array([tp, fn, fp, tn, tss, hss1, hss2, gss, recall, precision])\n",
    "\n",
    "\n",
    "    #joblib.dump(classifier, data_dir + \"mlp_model.pkl\")\n",
    "\n",
    "    #loaded_mlp_model = joblib.load(data_dir + \"mlp_model.pkl\")\n",
    "    \n",
    "    return output_values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32e9fd1e",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "127986e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_results(reslut, name):\n",
    "    data_dir = \"/Users/samskanderi/Documents/Research_Project/SWANSF/code/results/\"\n",
    "\n",
    "    with open(data_dir + name + \".pkl\", 'wb') as f:\n",
    "        pickle.dump(reslut, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c7bc689",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5b280418",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(73492, 216): SVM Classifier is Done! \n",
      "\n",
      "(73492, 216): SVM Classifier is Done! \n",
      "\n",
      "(73492, 216): SVM Classifier is Done! \n",
      "\n",
      "(73492, 216): SVM Classifier is Done! \n",
      "\n",
      "(88557, 216): SVM Classifier is Done! \n",
      "\n",
      "(88557, 216): SVM Classifier is Done! \n",
      "\n",
      "(88557, 216): SVM Classifier is Done! \n",
      "\n",
      "(42510, 216): SVM Classifier is Done! \n",
      "\n",
      "(42510, 216): SVM Classifier is Done! \n",
      "\n",
      "(51261, 216): SVM Classifier is Done! \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# SVM NewFeatures\n",
    "svm_newf = kfold_training('SVM', X_train_NewF_ZM, Y_train_NewF_ZM, svm_model, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a14a0c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_results(svm_newf, \"SVM_NewFeatures_Results\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5ce17de",
   "metadata": {},
   "source": [
    "## MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4dd95319",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2768/2768 [==============================] - 1s 268us/step\n",
      "(73492, 216): MLP Classifier is Done! \n",
      "\n",
      "1329/1329 [==============================] - 0s 268us/step\n",
      "(73492, 216): MLP Classifier is Done! \n",
      "\n",
      "1602/1602 [==============================] - 0s 269us/step\n",
      "(73492, 216): MLP Classifier is Done! \n",
      "\n",
      "2356/2356 [==============================] - 1s 274us/step\n",
      "(73492, 216): MLP Classifier is Done! \n",
      "\n",
      "1329/1329 [==============================] - 0s 271us/step\n",
      "(88557, 216): MLP Classifier is Done! \n",
      "\n",
      "1602/1602 [==============================] - 0s 268us/step\n",
      "(88557, 216): MLP Classifier is Done! \n",
      "\n",
      "2356/2356 [==============================] - 1s 268us/step\n",
      "(88557, 216): MLP Classifier is Done! \n",
      "\n",
      "1602/1602 [==============================] - 0s 272us/step\n",
      "(42510, 216): MLP Classifier is Done! \n",
      "\n",
      "2356/2356 [==============================] - 1s 270us/step\n",
      "(42510, 216): MLP Classifier is Done! \n",
      "\n",
      "2356/2356 [==============================] - 1s 268us/step\n",
      "(51261, 216): MLP Classifier is Done! \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# MLPClassifier NewFeatures\n",
    "mlp_newf = kfold_training('MLP', X_train_NewF_ZM, Y_train_NewF_ZM, mlp_model, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "097d194e",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_results(mlp_newf, \"MLPClassifier_NewFeatures_Results\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e702be07",
   "metadata": {},
   "source": [
    "### Rocket "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b24408d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(73492, 1): Rocket Classifier is Done! \n",
      "\n",
      "(73492, 1): Rocket Classifier is Done! \n",
      "\n",
      "(73492, 1): Rocket Classifier is Done! \n",
      "\n",
      "(73492, 1): Rocket Classifier is Done! \n",
      "\n",
      "(88557, 1): Rocket Classifier is Done! \n",
      "\n",
      "(88557, 1): Rocket Classifier is Done! \n",
      "\n",
      "(88557, 1): Rocket Classifier is Done! \n",
      "\n",
      "(42510, 1): Rocket Classifier is Done! \n",
      "\n",
      "(42510, 1): Rocket Classifier is Done! \n",
      "\n",
      "(51261, 1): Rocket Classifier is Done! \n",
      "\n"
     ]
    }
   ],
   "source": [
    "rocket_newf = kfold_training('Rocket', X_train_NewF_ZM, Y_train_NewF_ZM, rocket_model, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6ac1c1a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_results(rocket_newf, \"Rocket_NewFeatures_Results\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c43112c",
   "metadata": {},
   "source": [
    "### TimeSeriesForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fc2f461e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(73492, 216): TSF Classifier is Done! \n",
      "\n",
      "(73492, 216): TSF Classifier is Done! \n",
      "\n",
      "(73492, 216): TSF Classifier is Done! \n",
      "\n",
      "(73492, 216): TSF Classifier is Done! \n",
      "\n",
      "(88557, 216): TSF Classifier is Done! \n",
      "\n",
      "(88557, 216): TSF Classifier is Done! \n",
      "\n",
      "(88557, 216): TSF Classifier is Done! \n",
      "\n",
      "(42510, 216): TSF Classifier is Done! \n",
      "\n",
      "(42510, 216): TSF Classifier is Done! \n",
      "\n",
      "(51261, 216): TSF Classifier is Done! \n",
      "\n"
     ]
    }
   ],
   "source": [
    "tsf_newf = kfold_training('TSF', X_train_NewF_ZM, Y_train_NewF_ZM, tsf_model, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5b25573a",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_results(tsf_newf, \"TSF_NewFeatures_Results\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b2a0e73",
   "metadata": {},
   "source": [
    "### LSTM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "26bef0fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_partitions = 5\n",
    "X_train_NewF_ZM_3D = []\n",
    "for i in range(0,num_partitions):\n",
    "    X_train_NewF_ZM_3D.append(X_train_NewF_ZM[i].reshape(X_train_NewF_ZM[i].shape[0], 24, 9).transpose(0, 2, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f461da91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2768/2768 [==============================] - 5s 2ms/step\n",
      "(73492, 9, 24): LSTM Classifier is Done! \n",
      "\n",
      "1329/1329 [==============================] - 2s 2ms/step\n",
      "(73492, 9, 24): LSTM Classifier is Done! \n",
      "\n",
      "1602/1602 [==============================] - 3s 2ms/step\n",
      "(73492, 9, 24): LSTM Classifier is Done! \n",
      "\n",
      "2356/2356 [==============================] - 4s 2ms/step\n",
      "(73492, 9, 24): LSTM Classifier is Done! \n",
      "\n",
      "1329/1329 [==============================] - 2s 2ms/step\n",
      "(88557, 9, 24): LSTM Classifier is Done! \n",
      "\n",
      "1602/1602 [==============================] - 3s 2ms/step\n",
      "(88557, 9, 24): LSTM Classifier is Done! \n",
      "\n",
      "2356/2356 [==============================] - 4s 2ms/step\n",
      "(88557, 9, 24): LSTM Classifier is Done! \n",
      "\n",
      "1602/1602 [==============================] - 3s 2ms/step\n",
      "(42510, 9, 24): LSTM Classifier is Done! \n",
      "\n",
      "2356/2356 [==============================] - 4s 2ms/step\n",
      "(42510, 9, 24): LSTM Classifier is Done! \n",
      "\n",
      "2356/2356 [==============================] - 4s 2ms/step\n",
      "(51261, 9, 24): LSTM Classifier is Done! \n",
      "\n"
     ]
    }
   ],
   "source": [
    "lstm_newf = kfold_training('LSTM', X_train_NewF_ZM_3D, Y_train_NewF_ZM, lstm_model, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "803903cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_results(lstm_newf, \"LSTM_NewFeatures_Results\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f187740",
   "metadata": {},
   "source": [
    "### CNN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "89109128",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_partitions = 5\n",
    "X_train_NewF_ZM_3D = []\n",
    "for i in range(0,num_partitions):\n",
    "    X_train_NewF_ZM_3D.append(X_train_NewF_ZM[i].reshape(X_train_NewF_ZM[i].shape[0], 24, 9).transpose(0, 2, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1065e28e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_newf = kfold_training('CNN', X_train_NewF_ZM_3D, Y_train_NewF_ZM, cnn_model, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ad43dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_results(cnn_newf, \"CNN_NewFeatures_Results\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0fc66c6",
   "metadata": {},
   "source": [
    "# Comparison "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3941d553",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"/Users/samskanderi/Documents/Research_Project/SWANSF/code/results/\"\n",
    "with open(data_dir + 'SVM_NewFeatures_Results' + \".pkl\", 'rb') as f:\n",
    "    svm_newf=pickle.load(f)\n",
    "with open(data_dir + 'MLPClassifier_NewFeatures_Results' + \".pkl\", 'rb') as f:\n",
    "    mlp_newf=pickle.load(f)\n",
    "with open(data_dir + 'Rocket_NewFeatures_Results' + \".pkl\", 'rb') as f:\n",
    "    rocket_newf=pickle.load(f)\n",
    "with open(data_dir + 'TSF_NewFeatures_Results' + \".pkl\", 'rb') as f:\n",
    "    tsf_newf=pickle.load(f)\n",
    "\n",
    "\n",
    "\n",
    "names = ['SVM', 'MLP', 'Rocket', 'TSF']\n",
    "values = np.array([svm_newf, mlp_newf, rocket_newf, tsf_newf])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "88522bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_results(names, values):\n",
    "    np.printoptions(precision=4, suppress=True)\n",
    "    for i in range(0, values.shape[1]):\n",
    "        print(\"P_Train = \"+ str(values[0,i,0]) + \" & \" + \"P_Test = \" + str(values[0,i,1]))\n",
    "        for j in range(0, values.shape[0]):\n",
    "            print(names[j] + ' :' +  ' TP={:.0f}'.format(values[j,i,2]) + ' FN={:.0f}'.format(values[j,i,3]) + ' FP={:.0f}'.format(values[j,i,4])\n",
    "                 + ' TN={:.0f}'.format(values[j,i,5]) + ' TSS={:.3f}'.format(values[j,i,6]) + ' HSS1={:.3f}'.format(values[j,i,7]) + ' HSS2={:.3f}'.format(values[j,i,8])\n",
    "                 + ' GSS={:.3f}'.format(values[j,i,9]) + ' Recall={:.3f}'.format(values[j,i,10]) + ' Precision={:.3f}'.format(values[j,i,11]))\n",
    "        print('\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9688f338",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P_Train = 1.0 & P_Test = 2.0\n",
      "SVM : TP=206 FN=1195 FP=176 TN=86980 TSS=0.145 HSS1=0.226 HSS2=0.227 GSS=199.957 Recall=0.147 Precision=0.461\n",
      "MLP : TP=215 FN=1186 FP=366 TN=86790 TSS=0.149 HSS1=0.210 HSS2=0.210 GSS=205.808 Recall=0.153 Precision=0.630\n",
      "Rocket : TP=33 FN=1368 FP=66 TN=87090 TSS=0.023 HSS1=0.042 HSS2=0.043 GSS=31.434 Recall=0.024 Precision=0.667\n",
      "TSF : TP=140 FN=1261 FP=186 TN=86970 TSS=0.098 HSS1=0.157 HSS2=0.158 GSS=134.843 Recall=0.100 Precision=0.571\n",
      "\n",
      "\n",
      "P_Train = 1.0 & P_Test = 3.0\n",
      "SVM : TP=67 FN=1357 FP=8 TN=41078 TSS=0.047 HSS1=0.086 HSS2=0.089 GSS=64.488 Recall=0.047 Precision=0.107\n",
      "MLP : TP=58 FN=1366 FP=70 TN=41016 TSS=0.039 HSS1=0.070 HSS2=0.071 GSS=53.712 Recall=0.041 Precision=0.547\n",
      "Rocket : TP=93 FN=1331 FP=164 TN=40922 TSS=0.061 HSS1=0.101 HSS2=0.103 GSS=84.391 Recall=0.065 Precision=0.638\n",
      "TSF : TP=176 FN=1248 FP=163 TN=40923 TSS=0.120 HSS1=0.189 HSS2=0.192 GSS=164.644 Recall=0.124 Precision=0.481\n",
      "\n",
      "\n",
      "P_Train = 1.0 & P_Test = 4.0\n",
      "SVM : TP=40 FN=1125 FP=2 TN=50094 TSS=0.034 HSS1=0.065 HSS2=0.066 GSS=39.045 Recall=0.034 Precision=0.048\n",
      "MLP : TP=331 FN=834 FP=95 TN=50001 TSS=0.282 HSS1=0.409 HSS2=0.412 GSS=321.318 Recall=0.284 Precision=0.223\n",
      "Rocket : TP=74 FN=1091 FP=24 TN=50072 TSS=0.063 HSS1=0.114 HSS2=0.116 GSS=71.773 Recall=0.064 Precision=0.245\n",
      "TSF : TP=125 FN=1040 FP=12 TN=50084 TSS=0.107 HSS1=0.188 HSS2=0.191 GSS=121.886 Recall=0.107 Precision=0.088\n",
      "\n",
      "\n",
      "P_Train = 1.0 & P_Test = 5.0\n",
      "SVM : TP=41 FN=949 FP=2 TN=74373 TSS=0.041 HSS1=0.078 HSS2=0.079 GSS=40.435 Recall=0.041 Precision=0.047\n",
      "MLP : TP=232 FN=758 FP=152 TN=74223 TSS=0.232 HSS1=0.333 HSS2=0.334 GSS=226.956 Recall=0.234 Precision=0.396\n",
      "Rocket : TP=84 FN=906 FP=73 TN=74302 TSS=0.084 HSS1=0.143 HSS2=0.145 GSS=81.938 Recall=0.085 Precision=0.465\n",
      "TSF : TP=55 FN=935 FP=65 TN=74310 TSS=0.055 HSS1=0.097 HSS2=0.097 GSS=53.424 Recall=0.056 Precision=0.542\n",
      "\n",
      "\n",
      "P_Train = 2.0 & P_Test = 3.0\n",
      "SVM : TP=97 FN=1327 FP=20 TN=41066 TSS=0.068 HSS1=0.121 HSS2=0.125 GSS=93.081 Recall=0.068 Precision=0.171\n",
      "MLP : TP=189 FN=1235 FP=88 TN=40998 TSS=0.131 HSS1=0.214 HSS2=0.218 GSS=179.721 Recall=0.133 Precision=0.318\n",
      "Rocket : TP=307 FN=1117 FP=226 TN=40860 TSS=0.210 HSS1=0.301 HSS2=0.304 GSS=289.146 Recall=0.216 Precision=0.424\n",
      "TSF : TP=105 FN=1319 FP=60 TN=41026 TSS=0.072 HSS1=0.126 HSS2=0.129 GSS=99.473 Recall=0.074 Precision=0.364\n",
      "\n",
      "\n",
      "P_Train = 2.0 & P_Test = 4.0\n",
      "SVM : TP=0 FN=1165 FP=13 TN=50083 TSS=-0.000 HSS1=-0.001 HSS2=-0.001 GSS=-0.295 Recall=0.000 Precision=1.000\n",
      "MLP : TP=143 FN=1022 FP=135 TN=49961 TSS=0.120 HSS1=0.191 HSS2=0.193 GSS=136.682 Recall=0.123 Precision=0.486\n",
      "Rocket : TP=102 FN=1063 FP=46 TN=50050 TSS=0.087 HSS1=0.151 HSS2=0.153 GSS=98.636 Recall=0.088 Precision=0.311\n",
      "TSF : TP=88 FN=1077 FP=19 TN=50077 TSS=0.075 HSS1=0.135 HSS2=0.137 GSS=85.568 Recall=0.076 Precision=0.178\n",
      "\n",
      "\n",
      "P_Train = 2.0 & P_Test = 5.0\n",
      "SVM : TP=37 FN=953 FP=11 TN=74364 TSS=0.037 HSS1=0.070 HSS2=0.071 GSS=36.369 Recall=0.037 Precision=0.229\n",
      "MLP : TP=307 FN=683 FP=470 TN=73905 TSS=0.304 HSS1=0.340 HSS2=0.340 GSS=296.793 Recall=0.310 Precision=0.605\n",
      "Rocket : TP=149 FN=841 FP=167 TN=74208 TSS=0.148 HSS1=0.223 HSS2=0.224 GSS=144.849 Recall=0.151 Precision=0.528\n",
      "TSF : TP=96 FN=894 FP=100 TN=74275 TSS=0.096 HSS1=0.158 HSS2=0.159 GSS=93.425 Recall=0.097 Precision=0.510\n",
      "\n",
      "\n",
      "P_Train = 3.0 & P_Test = 4.0\n",
      "SVM : TP=202 FN=963 FP=2 TN=50094 TSS=0.173 HSS1=0.290 HSS2=0.294 GSS=197.364 Recall=0.173 Precision=0.010\n",
      "MLP : TP=449 FN=716 FP=1214 TN=48882 TSS=0.361 HSS1=0.299 HSS2=0.299 GSS=411.205 Recall=0.385 Precision=0.730\n",
      "Rocket : TP=299 FN=866 FP=156 TN=49940 TSS=0.254 HSS1=0.361 HSS2=0.363 GSS=288.659 Recall=0.257 Precision=0.343\n",
      "TSF : TP=217 FN=948 FP=170 TN=49926 TSS=0.183 HSS1=0.271 HSS2=0.273 GSS=208.205 Recall=0.186 Precision=0.439\n",
      "\n",
      "\n",
      "P_Train = 3.0 & P_Test = 5.0\n",
      "SVM : TP=284 FN=706 FP=151 TN=74224 TSS=0.285 HSS1=0.394 HSS2=0.395 GSS=278.286 Recall=0.287 Precision=0.347\n",
      "MLP : TP=503 FN=487 FP=898 TN=73477 TSS=0.496 HSS1=0.412 HSS2=0.412 GSS=484.596 Recall=0.508 Precision=0.641\n",
      "Rocket : TP=550 FN=440 FP=1434 TN=72941 TSS=0.536 HSS1=0.359 HSS2=0.360 GSS=523.938 Recall=0.556 Precision=0.723\n",
      "TSF : TP=184 FN=806 FP=197 TN=74178 TSS=0.183 HSS1=0.263 HSS2=0.264 GSS=178.995 Recall=0.186 Precision=0.517\n",
      "\n",
      "\n",
      "P_Train = 4.0 & P_Test = 5.0\n",
      "SVM : TP=431 FN=559 FP=903 TN=73472 TSS=0.423 HSS1=0.361 HSS2=0.362 GSS=413.476 Recall=0.435 Precision=0.677\n",
      "MLP : TP=763 FN=227 FP=3351 TN=71024 TSS=0.726 HSS1=0.284 HSS2=0.291 GSS=708.958 Recall=0.771 Precision=0.815\n",
      "Rocket : TP=563 FN=427 FP=1280 TN=73095 TSS=0.551 HSS1=0.387 HSS2=0.388 GSS=538.790 Recall=0.569 Precision=0.695\n",
      "TSF : TP=189 FN=801 FP=231 TN=74144 TSS=0.188 HSS1=0.262 HSS2=0.263 GSS=183.483 Recall=0.191 Precision=0.550\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "compare_results(names, values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db226f87",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
