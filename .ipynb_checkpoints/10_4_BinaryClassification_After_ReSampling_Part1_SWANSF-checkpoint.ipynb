{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2aef2ab6",
   "metadata": {},
   "source": [
    "# Rocket, TSF, LSTM, RNN, GRU, 1D-CNN on Cocatenation (After Sampling)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7cbdd32",
   "metadata": {},
   "source": [
    "# Train Test Split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df67175e",
   "metadata": {},
   "source": [
    "## Stratified Cross validation (k = 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13c959d3",
   "metadata": {},
   "source": [
    "P1 Train and P2 Test, P1 Train and P3 Test, P1 Train and P4 Test, P1 Train and P5 Test\n",
    "P2 Train and P3 Test, P2 Train and P4 Test, P2 Train and P5 Test\n",
    "P3 Train and P4 Test, P3 Train and P5 Test\n",
    "P4 Train and P5 Test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea62f006",
   "metadata": {},
   "source": [
    "# Evaluation Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "78559b58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# float(\"{:.2f}\".format(13.949999999999999))\n",
    "\n",
    "def TSS(TP,TN,FP,FN):\n",
    "    TSS_value = (TP / (TP + FN)) - (FP / (FP + TN))\n",
    "    return TSS_value\n",
    "\n",
    "def HSS1(TP,TN,FP,FN):\n",
    "    HSS1_value = (2 * (TP * TN - FP * FN)) / ((TP + FN) * (FN + TN) + (TP + FP) * (FP + TN))\n",
    "    return HSS1_value\n",
    "    \n",
    "def HSS2(TP,TN,FP,FN):\n",
    "    HSS2_value = (2 * (TP * TN - FP * FN)) / ((TP + FP) * (FN + TN) + (TP + FN) * (FP + TN))\n",
    "    return HSS2_value\n",
    "\n",
    "def GSS(TP,TN,FP,FN):\n",
    "    GSS_value = (TP - (TP + FP) * (TP + FN) / (TP + FP + FN + TN))\n",
    "    return GSS_value\n",
    "\n",
    "def Recall(TP,TN,FP,FN):\n",
    "    Recall_value = (TP) / (TP + FN)\n",
    "    return Recall_value\n",
    "\n",
    "def FPR(TP,TN,FP,FN):\n",
    "    fpr_value = (FP) / (FP + TN)\n",
    "    return fpr_value\n",
    "\n",
    "def Accuracy(TP,TN,FP,FN):\n",
    "    accuracy_value = (TP + TN) / (TP + TN + FP + FN)\n",
    "    return accuracy_value\n",
    "\n",
    "def Precision(TP,TN,FP,FN):\n",
    "    precision_value = (TP) / (TP + FP)\n",
    "    return precision_value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "342a8fa7",
   "metadata": {},
   "source": [
    "# Loading the Final Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4f52133",
   "metadata": {},
   "source": [
    "## Concatenation "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70d7efdb",
   "metadata": {},
   "source": [
    "#### RUS-Tomek_GNI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "777f08e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P1 Nan-Value: False\n",
      "P2 Nan-Value: False\n",
      "P3 Nan-Value: False\n",
      "P4 Nan-Value: False\n",
      "P5 Nan-Value: False\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "data_dir = \"/Users/samskanderi/Documents/Research_Project/SWANSF/code/8_3_FinalData_OUSampling_Concatenation_LSBZM_KnnImputation/\"\n",
    "X_train_concat_ZM_RTS = []\n",
    "Y_train_concat_ZM_RTS = []\n",
    "\n",
    "\n",
    "num_partitions = 5\n",
    "\n",
    "for i in range(0,num_partitions):\n",
    "    with open(data_dir + \"RUS_Tomek_GNI_\" +\"Partition\" + str(i+1) + \"_WithoutC_Concatenation_LSBZM_KnnImputation\" +\".pkl\", 'rb') as f:\n",
    "        X_train_concat_ZM_RTS.append(pickle.load(f))\n",
    "    with open(data_dir + \"RUS_Tomek_GNI_\" + \"Partition\" + str(i+1) + \"_Labels_WithoutC_Concatenation_LSBZM_KnnImputation\" +\".pkl\", 'rb') as f:\n",
    "        Y_train_concat_ZM_RTS.append(pickle.load(f))\n",
    "    print(\"P\"+str(i+1)+\" Nan-Value: \"+ str(np.isnan(X_train_concat_ZM_RTS[i]).any() or np.isinf(X_train_concat_ZM_RTS[i]).any()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17bfcf0e",
   "metadata": {},
   "source": [
    "#### RUS-Tomek_TimeGAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "013c9a76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P1 Nan-Value: False\n",
      "P2 Nan-Value: False\n",
      "P3 Nan-Value: False\n",
      "P4 Nan-Value: False\n",
      "P5 Nan-Value: False\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "data_dir = \"/Users/samskanderi/Documents/Research_Project/SWANSF/code/8_3_FinalData_OUSampling_Concatenation_LSBZM_KnnImputation/\"\n",
    "X_train_concat_ZM_RTA = []\n",
    "Y_train_concat_ZM_RTA = []\n",
    "\n",
    "\n",
    "num_partitions = 5\n",
    "\n",
    "for i in range(0,num_partitions):\n",
    "    with open(data_dir + \"RUS_Tomek_TimeGAN_\" +\"Partition\" + str(i+1) + \"_WithoutC_Concatenation_LSBZM_KnnImputation\" +\".pkl\", 'rb') as f:\n",
    "        X_train_concat_ZM_RTA.append(pickle.load(f))\n",
    "    with open(data_dir + \"RUS_Tomek_TimeGAN_\" + \"Partition\" + str(i+1) + \"_Labels_WithoutC_Concatenation_LSBZM_KnnImputation\" +\".pkl\", 'rb') as f:\n",
    "        Y_train_concat_ZM_RTA.append(pickle.load(f))\n",
    "    print(\"P\"+str(i+1)+\" Nan-Value: \"+ str(np.isnan(X_train_concat_ZM_RTA[i]).any() or np.isinf(X_train_concat_ZM_RTA[i]).any()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd16e3c3",
   "metadata": {},
   "source": [
    "#### GNI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d53204d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P1 Nan-Value: False\n",
      "P2 Nan-Value: False\n",
      "P3 Nan-Value: False\n",
      "P4 Nan-Value: False\n",
      "P5 Nan-Value: False\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "data_dir = \"/Users/samskanderi/Documents/Research_Project/SWANSF/code/8_4_FinalData_OSampling_Concatenation_LSBZM_KnnImputation/\"\n",
    "X_train_concat_ZM_S = []\n",
    "Y_train_concat_ZM_S = []\n",
    "\n",
    "\n",
    "num_partitions = 5\n",
    "\n",
    "for i in range(0,num_partitions):\n",
    "    with open(data_dir + \"GaussianNoise_\" +\"Partition\" + str(i+1) + \"_OSampling_WithoutC_Concatenation_LSBZM_KnnImputation\" +\".pkl\", 'rb') as f:\n",
    "        X_train_concat_ZM_S.append(pickle.load(f))\n",
    "    with open(data_dir + \"GaussianNoise_\" + \"Partition\" + str(i+1) + \"_Labels_OSampling_WithoutC_Concatenation_LSBZM_KnnImputation\" +\".pkl\", 'rb') as f:\n",
    "        Y_train_concat_ZM_S.append(pickle.load(f))\n",
    "    print(\"P\"+str(i+1)+\" Nan-Value: \"+ str(np.isnan(X_train_concat_ZM_S[i]).any() or np.isinf(X_train_concat_ZM_S[i]).any()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2fce791",
   "metadata": {},
   "source": [
    "#### TimeGAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c08af0de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P1 Nan-Value: False\n",
      "P2 Nan-Value: False\n",
      "P3 Nan-Value: False\n",
      "P4 Nan-Value: False\n",
      "P5 Nan-Value: False\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "data_dir = \"/Users/samskanderi/Documents/Research_Project/SWANSF/code/8_4_FinalData_OSampling_Concatenation_LSBZM_KnnImputation/\"\n",
    "X_train_concat_ZM_A = []\n",
    "Y_train_concat_ZM_A = []\n",
    "\n",
    "\n",
    "num_partitions = 5\n",
    "\n",
    "for i in range(0,num_partitions):\n",
    "    with open(data_dir + \"TimeGAN_\" +\"Partition\" + str(i+1) + \"_OSampling_WithoutC_Concatenation_LSBZM_KnnImputation\" +\".pkl\", 'rb') as f:\n",
    "        X_train_concat_ZM_A.append(pickle.load(f))\n",
    "    with open(data_dir + \"TimeGAN_\" + \"Partition\" + str(i+1) + \"_Labels_OSampling_WithoutC_Concatenation_LSBZM_KnnImputation\" +\".pkl\", 'rb') as f:\n",
    "        Y_train_concat_ZM_A.append(pickle.load(f))\n",
    "    print(\"P\"+str(i+1)+\" Nan-Value: \"+ str(np.isnan(X_train_concat_ZM_A[i]).any() or np.isinf(X_train_concat_ZM_A[i]).any()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fad7a417",
   "metadata": {},
   "source": [
    "#### Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f80dc488",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P1 Nan-Value: False\n",
      "P2 Nan-Value: False\n",
      "P3 Nan-Value: False\n",
      "P4 Nan-Value: False\n",
      "P5 Nan-Value: False\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "data_dir = \"/Users/samskanderi/Documents/Research_Project/SWANSF/code/5_4_FinalData_Concatenation_LSBZM_KnnImputation/\"\n",
    "X_test_concat_ZM = []\n",
    "Y_test_concat_ZM = []\n",
    "\n",
    "\n",
    "num_partitions = 5\n",
    "\n",
    "for i in range(0,num_partitions):\n",
    "    with open(data_dir + \"Partition\" + str(i+1) + \"_Concatenation_LSBZM_KnnImputation\" + \".pkl\", 'rb') as f:\n",
    "        X_test_concat_ZM.append(pickle.load(f))\n",
    "    print(\"P\"+str(i+1)+\" Nan-Value: \"+ str(np.isnan(X_test_concat_ZM[i]).any() or np.isinf(X_test_concat_ZM[i]).any()))\n",
    "    \n",
    "    with open(data_dir + \"Partition\" + str(i+1) + \"_Labels_Concatenation_LSBZM_KnnImputation\" + \".pkl\", 'rb') as f:\n",
    "        Y_test_concat_ZM.append(pickle.load(f))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e879937b",
   "metadata": {},
   "source": [
    "# Useful Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "69a74f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kfold_training(name, X_train, Y_train, X_test, Y_test, training_func, num):\n",
    "    kfold = np.array([[4,5],[1,2],[1,3],[1,4],[1,5],[2,3],[2,4],[2,5],[3,4],[3,5]])\n",
    "    metrics = []\n",
    "    metrics_values = np.array([])\n",
    "    \n",
    "    for i in range(0, num):\n",
    "        train_index = kfold[i,0]\n",
    "        test_index = kfold[i,1]\n",
    "        metrics_values = training_func(X_train[train_index-1], Y_train[train_index-1], X_test[test_index-1], Y_test[test_index-1])\n",
    "        while (metrics_values[4]< 0.4):\n",
    "            metrics_values = training_func(X_train[train_index-1], Y_train[train_index-1], X_test[test_index-1], Y_test[test_index-1])\n",
    "        metrics.append(np.append(np.append(train_index, test_index), metrics_values))\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56a024ab",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b13583cb",
   "metadata": {},
   "source": [
    "## Rocket (RidgeClassifierCV) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8a7ff942",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROCKET with RidgeClassifierCV\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.linear_model import RidgeClassifierCV\n",
    "from sktime.transformations.panel.rocket import Rocket\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import joblib\n",
    "from sktime.datatypes._panel._convert import from_2d_array_to_nested\n",
    "\n",
    "def rocket_model(X_train, Y_train, X_test, Y_test, rocket_kernels=1500):\n",
    "\n",
    "    data_dir = \"/Users/samskanderi/Documents/Research_Project/SWANSF/code/models/rocket/\"\n",
    "    \n",
    "    X_train = from_2d_array_to_nested(X_train)\n",
    "    X_test = from_2d_array_to_nested(X_test)\n",
    "\n",
    "    rocket = Rocket(num_kernels=rocket_kernels)\n",
    "    rocket.fit(X_train)\n",
    "    X_train_transform = rocket.transform(X_train)\n",
    "        \n",
    "    classifier = RidgeClassifierCV()\n",
    "    classifier.fit(X_train_transform, Y_train)\n",
    "    \n",
    "    X_test_transform = rocket.transform(X_test)\n",
    "    \n",
    "    y_pred = classifier.predict(X_test_transform)\n",
    "    \n",
    "    print(str(X_train.shape)+': Rocket Classifier is Done! \\n')\n",
    "\n",
    "    confusion = confusion_matrix(Y_test, y_pred)\n",
    "    tn, fp, fn, tp = confusion.ravel()\n",
    "\n",
    "    tss = TSS(tp,tn,fp,fn)\n",
    "    hss1 = HSS1(tp,tn,fp,fn)\n",
    "    hss2 = HSS2(tp,tn,fp,fn)\n",
    "    gss = GSS(tp,tn,fp,fn)\n",
    "    recall = Recall(tp,tn,fp,fn)\n",
    "    precision = Precision(tp,tn,fp,fn)\n",
    "    \n",
    "    output_values = np.array([tp, fn, fp, tn, tss, hss1, hss2, gss, recall, precision])\n",
    "\n",
    "\n",
    "    #joblib.dump(classifier, data_dir + \"rocket_model.pkl\")\n",
    "\n",
    "    #loaded_rocket_model = joblib.load(data_dir + \"rocket_model_sgd.pkl\")\n",
    "    \n",
    "    return output_values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8840de35",
   "metadata": {},
   "source": [
    "## TimeSeriesForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "06c0fef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TimeSeriesForest\n",
    "\n",
    "from sktime.classification.interval_based import TimeSeriesForestClassifier\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import joblib\n",
    "\n",
    "def tsf_model(X_train, Y_train, X_test, Y_test, tsf_estimator=60):\n",
    "\n",
    "    data_dir = \"/Users/samskanderi/Documents/Research_Project/SWANSF/code/models/TSF/\"\n",
    "    \n",
    "    \n",
    "    tsf_classifier = TimeSeriesForestClassifier(n_estimators=tsf_estimator)\n",
    "    tsf_classifier.fit(X_train, Y_train)\n",
    "    y_pred = tsf_classifier.predict(X_test)\n",
    "    \n",
    "    print(str(X_train.shape)+': TSF Classifier is Done! \\n')\n",
    "    \n",
    "\n",
    "    confusion = confusion_matrix(Y_test, y_pred)\n",
    "    tn, fp, fn, tp = confusion.ravel()\n",
    "\n",
    "    tss = TSS(tp,tn,fp,fn)\n",
    "    hss1 = HSS1(tp,tn,fp,fn)\n",
    "    hss2 = HSS2(tp,tn,fp,fn)\n",
    "    gss = GSS(tp,tn,fp,fn)\n",
    "    recall = Recall(tp,tn,fp,fn)\n",
    "    precision = Precision(tp,tn,fp,fn)\n",
    "    \n",
    "    output_values = np.array([tp, fn, fp, tn, tss, hss1, hss2, gss, recall, precision])\n",
    "\n",
    "\n",
    "    #joblib.dump(classifier, data_dir + \"tsf_model.pkl\")\n",
    "\n",
    "    #loaded_rocket_model = joblib.load(data_dir + \"tsf_model.pkl\")\n",
    "    \n",
    "    return output_values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18eb4d25",
   "metadata": {},
   "source": [
    "## LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "92a02e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, Dropout\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def lstm_model(X_train, Y_train, X_test, Y_test):\n",
    "    \n",
    "    data_dir = \"/Users/samskanderi/Documents/Research_Project/SWANSF/code/models/\"\n",
    "    \n",
    "    verbose, epochs, batch_size = 0, 15, 32\n",
    "    n_timesteps, n_features = 60, 24\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(120, input_shape=(n_timesteps,n_features)))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(120, activation='relu'))\n",
    "    model.add(Dense(2, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=keras.metrics.SpecificityAtSensitivity(sensitivity=0.98))\n",
    "    \n",
    "    model.fit(X_train, Y_train, epochs=epochs, batch_size=batch_size, verbose=verbose)\n",
    "    \n",
    "    best_threshold = 0.0\n",
    "    best_tss = 0.0\n",
    "    y_pred = model.predict(X_test)\n",
    "    # evaluate model\n",
    "    for i in range(1, 1000):\n",
    "\n",
    "        threshold = i / 1000 # Adjust the threshold as needed\n",
    "        y_pred_binary = (y_pred > threshold).astype(int)\n",
    "        confusion = confusion_matrix(Y_test, y_pred_binary)\n",
    "        tn, fp, fn, tp = confusion.ravel()\n",
    "        tss = TSS(tp,tn,fp,fn)\n",
    "        if tss > best_tss:\n",
    "            best_tss = tss\n",
    "            best_threshold = i / 1000\n",
    "        \n",
    "    \n",
    "    print(str(X_train.shape)+': LSTM Classifier is Done! \\n')\n",
    "\n",
    "\n",
    "    threshold = best_threshold # Adjust the threshold as needed\n",
    "    y_pred_binary = (y_pred > threshold).astype(int)\n",
    "    confusion = confusion_matrix(Y_test, y_pred_binary)\n",
    "    tn, fp, fn, tp = confusion.ravel()\n",
    "\n",
    "    tss = TSS(tp,tn,fp,fn)\n",
    "    hss1 = HSS1(tp,tn,fp,fn)\n",
    "    hss2 = HSS2(tp,tn,fp,fn)\n",
    "    gss = GSS(tp,tn,fp,fn)\n",
    "    recall = Recall(tp,tn,fp,fn)\n",
    "    precision = Precision(tp,tn,fp,fn)\n",
    "    \n",
    "    output_values = np.array([tp, fn, fp, tn, tss, hss1, hss2, gss, recall, precision])\n",
    "\n",
    "\n",
    "    #joblib.dump(classifier, data_dir + \"mlp_model.pkl\")\n",
    "\n",
    "    #loaded_mlp_model = joblib.load(data_dir + \"mlp_model.pkl\")\n",
    "    \n",
    "    return output_values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "694e693a",
   "metadata": {},
   "source": [
    "## 1D-CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "265014e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Dropout\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def cnn_model(X_train, Y_train, X_test, Y_test):\n",
    "    \n",
    "    data_dir = \"/Users/samskanderi/Documents/Research_Project/SWANSF/code/models/\"\n",
    "    \n",
    "    verbose, epochs, batch_size = 0, 15, 32\n",
    "    n_timesteps, n_features = 60, 24\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(filters=64, kernel_size=5, activation='relu', input_shape=(n_timesteps,n_features)))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    model.add(Conv1D(filters=128, kernel_size=5, activation='relu'))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(357, activation='relu'))\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dense(2, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=keras.metrics.SpecificityAtSensitivity(sensitivity=0.98))\n",
    "    \n",
    "    model.fit(X_train, Y_train, epochs=epochs, batch_size=batch_size, verbose=verbose)\n",
    "    \n",
    "    best_threshold = 0.0\n",
    "    best_tss = 0.0\n",
    "    y_pred = model.predict(X_test)\n",
    "    # evaluate model\n",
    "    for i in range(1, 1000):\n",
    "\n",
    "        threshold = i / 1000 # Adjust the threshold as needed\n",
    "        y_pred_binary = (y_pred > threshold).astype(int)\n",
    "        confusion = confusion_matrix(Y_test, y_pred_binary)\n",
    "        tn, fp, fn, tp = confusion.ravel()\n",
    "        tss = TSS(tp,tn,fp,fn)\n",
    "        if tss > best_tss:\n",
    "            best_tss = tss\n",
    "            best_threshold = i / 1000\n",
    "        \n",
    "    \n",
    "    print(str(X_train.shape)+': CNN Classifier is Done! \\n')\n",
    "\n",
    "\n",
    "    threshold = best_threshold # Adjust the threshold as needed\n",
    "    y_pred_binary = (y_pred > threshold).astype(int)\n",
    "    confusion = confusion_matrix(Y_test, y_pred_binary)\n",
    "    tn, fp, fn, tp = confusion.ravel()\n",
    "\n",
    "    tss = TSS(tp,tn,fp,fn)\n",
    "    hss1 = HSS1(tp,tn,fp,fn)\n",
    "    hss2 = HSS2(tp,tn,fp,fn)\n",
    "    gss = GSS(tp,tn,fp,fn)\n",
    "    recall = Recall(tp,tn,fp,fn)\n",
    "    precision = Precision(tp,tn,fp,fn)\n",
    "    \n",
    "    output_values = np.array([tp, fn, fp, tn, tss, hss1, hss2, gss, recall, precision])\n",
    "\n",
    "\n",
    "    #joblib.dump(classifier, data_dir + \"mlp_model.pkl\")\n",
    "\n",
    "    #loaded_mlp_model = joblib.load(data_dir + \"mlp_model.pkl\")\n",
    "    \n",
    "    return output_values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a74348c",
   "metadata": {},
   "source": [
    "## RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "445052a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import SimpleRNN, Dense, Dropout\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def rnn_model(X_train, Y_train, X_test, Y_test):\n",
    "    \n",
    "    data_dir = \"/Users/samskanderi/Documents/Research_Project/SWANSF/code/models/\"\n",
    "    \n",
    "    verbose, epochs, batch_size = 0, 15, 32\n",
    "    n_timesteps, n_features = 60, 24\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(SimpleRNN(units=120, activation='relu', input_shape=(n_timesteps,n_features)))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(120, activation='relu'))\n",
    "    model.add(Dense(2, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=keras.metrics.SpecificityAtSensitivity(sensitivity=0.98))\n",
    "    \n",
    "    model.fit(X_train, Y_train, epochs=epochs, batch_size=batch_size, verbose=verbose)\n",
    "\n",
    "\n",
    "    best_threshold = 0.0\n",
    "    best_tss = 0.0\n",
    "    y_pred = model.predict(X_test)\n",
    "    # evaluate model\n",
    "    for i in range(1, 1000):\n",
    "\n",
    "        threshold = i / 1000 # Adjust the threshold as needed\n",
    "        y_pred_binary = (y_pred > threshold).astype(int)\n",
    "        confusion = confusion_matrix(Y_test, y_pred_binary)\n",
    "        tn, fp, fn, tp = confusion.ravel()\n",
    "        tss = TSS(tp,tn,fp,fn)\n",
    "        if tss > best_tss:\n",
    "            best_tss = tss\n",
    "            best_threshold = i / 1000\n",
    "        \n",
    "    \n",
    "    print(str(X_train.shape)+': RNN Classifier is Done! \\n')\n",
    "\n",
    "\n",
    "    threshold = best_threshold # Adjust the threshold as needed\n",
    "    y_pred_binary = (y_pred > threshold).astype(int)\n",
    "    confusion = confusion_matrix(Y_test, y_pred_binary)\n",
    "    tn, fp, fn, tp = confusion.ravel()\n",
    "\n",
    "    tss = TSS(tp,tn,fp,fn)\n",
    "    hss1 = HSS1(tp,tn,fp,fn)\n",
    "    hss2 = HSS2(tp,tn,fp,fn)\n",
    "    gss = GSS(tp,tn,fp,fn)\n",
    "    recall = Recall(tp,tn,fp,fn)\n",
    "    precision = Precision(tp,tn,fp,fn)\n",
    "    \n",
    "    output_values = np.array([tp, fn, fp, tn, tss, hss1, hss2, gss, recall, precision])\n",
    "\n",
    "\n",
    "    #joblib.dump(classifier, data_dir + \"mlp_model.pkl\")\n",
    "\n",
    "    #loaded_mlp_model = joblib.load(data_dir + \"mlp_model.pkl\")\n",
    "    \n",
    "    return output_values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e51f840",
   "metadata": {},
   "source": [
    "## GRU "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "12073183",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import GRU, Dense, Dropout\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def gru_model(X_train, Y_train, X_test, Y_test):\n",
    "    \n",
    "    data_dir = \"/Users/samskanderi/Documents/Research_Project/SWANSF/code/models/\"\n",
    "    \n",
    "    verbose, epochs, batch_size = 0, 15, 32\n",
    "    n_timesteps, n_features = 60, 24\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(GRU(units=120, activation='relu', input_shape=(n_timesteps,n_features)))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(120, activation='relu'))\n",
    "    model.add(Dense(2, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=keras.metrics.SpecificityAtSensitivity(sensitivity=0.98))\n",
    "\n",
    "    model.fit(X_train, Y_train, epochs=epochs, batch_size=batch_size, verbose=verbose)\n",
    "    \n",
    "    best_threshold = 0.0\n",
    "    best_tss = 0.0\n",
    "    y_pred = model.predict(X_test)\n",
    "    # evaluate model\n",
    "    for i in range(1, 1000):\n",
    "\n",
    "        threshold = i / 1000 # Adjust the threshold as needed\n",
    "        y_pred_binary = (y_pred > threshold).astype(int)\n",
    "        confusion = confusion_matrix(Y_test, y_pred_binary)\n",
    "        tn, fp, fn, tp = confusion.ravel()\n",
    "        tss = TSS(tp,tn,fp,fn)\n",
    "        if tss > best_tss:\n",
    "            best_tss = tss\n",
    "            best_threshold = i / 1000\n",
    "        \n",
    "    \n",
    "    print(str(X_train.shape)+': GRU Classifier is Done! \\n')\n",
    "\n",
    "\n",
    "    threshold = best_threshold # Adjust the threshold as needed\n",
    "    y_pred_binary = (y_pred > threshold).astype(int)\n",
    "    confusion = confusion_matrix(Y_test, y_pred_binary)\n",
    "    tn, fp, fn, tp = confusion.ravel()\n",
    "\n",
    "    tss = TSS(tp,tn,fp,fn)\n",
    "    hss1 = HSS1(tp,tn,fp,fn)\n",
    "    hss2 = HSS2(tp,tn,fp,fn)\n",
    "    gss = GSS(tp,tn,fp,fn)\n",
    "    recall = Recall(tp,tn,fp,fn)\n",
    "    precision = Precision(tp,tn,fp,fn)\n",
    "    \n",
    "    output_values = np.array([tp, fn, fp, tn, tss, hss1, hss2, gss, recall, precision])\n",
    "\n",
    "\n",
    "    #joblib.dump(classifier, data_dir + \"mlp_model.pkl\")\n",
    "\n",
    "    #loaded_mlp_model = joblib.load(data_dir + \"mlp_model.pkl\")\n",
    "    \n",
    "    return output_values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a09b2613",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2fae2c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_results(reslut, name):\n",
    "    data_dir = \"/Users/samskanderi/Documents/Research_Project/SWANSF/code/results/\"\n",
    "\n",
    "    with open(data_dir + name + \".pkl\", 'wb') as f:\n",
    "        pickle.dump(reslut, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bab12c1",
   "metadata": {},
   "source": [
    "### Rocket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f9f997a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20000, 1): Rocket Classifier is Done! \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Rocket Concatenation\n",
    "rocket_concat_RTS = kfold_training('Rocket', X_train_concat_ZM_RTS, Y_train_concat_ZM_RTS, X_test_concat_ZM, Y_test_concat_ZM, rocket_model, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e26f1cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_results(rocket_concat_RTS, \"Rocket_RusTomekGNI_WithoutC_Concatenation_Results\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b3672701",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19320, 1): Rocket Classifier is Done! \n",
      "\n"
     ]
    }
   ],
   "source": [
    "rocket_concat_RTA = kfold_training('Rocket', X_train_concat_ZM_RTA, Y_train_concat_ZM_RTA, X_test_concat_ZM, Y_test_concat_ZM, rocket_model, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4eed4771",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_results(rocket_concat_RTA, \"Rocket_RusTomekTimeGAN_WithoutC_Concatenation_Results\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d4d48f83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(88280, 1): Rocket Classifier is Done! \n",
      "\n"
     ]
    }
   ],
   "source": [
    "rocket_concat_S = kfold_training('Rocket', X_train_concat_ZM_S, Y_train_concat_ZM_S, X_test_concat_ZM, Y_test_concat_ZM, rocket_model, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "02d8d9bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_results(rocket_concat_S, \"Rocket_GNI_WithoutC_Concatenation_Results\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "57ecba87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(87245, 1): Rocket Classifier is Done! \n",
      "\n"
     ]
    }
   ],
   "source": [
    "rocket_concat_A = kfold_training('Rocket', X_train_concat_ZM_A, Y_train_concat_ZM_A, X_test_concat_ZM, Y_test_concat_ZM, rocket_model, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bb6ba0dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_results(rocket_concat_A, \"Rocket_TimeGAN_WithoutC_Concatenation_Results\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb1740fb",
   "metadata": {},
   "source": [
    "### TSF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cb290ad0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20000, 1440): TSF Classifier is Done! \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# TSF Concatenation\n",
    "tsf_concat_RTS = kfold_training('TSF', X_train_concat_ZM_RTS, Y_train_concat_ZM_RTS, X_test_concat_ZM, Y_test_concat_ZM, tsf_model, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "85f9558f",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_results(tsf_concat_RTS, \"TSF_RusTomekGNI_WithoutC_Concatenation_Results\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a62f5cb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19320, 1440): TSF Classifier is Done! \n",
      "\n"
     ]
    }
   ],
   "source": [
    "tsf_concat_RTA = kfold_training('TSF', X_train_concat_ZM_RTA, Y_train_concat_ZM_RTA, X_test_concat_ZM, Y_test_concat_ZM, tsf_model, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b6557504",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_results(tsf_concat_RTA, \"TSF_RusTomekTimeGAN_WithoutC_Concatenation_Results\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cda5fec1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(88280, 1440): TSF Classifier is Done! \n",
      "\n"
     ]
    }
   ],
   "source": [
    "tsf_concat_S = kfold_training('TSF', X_train_concat_ZM_S, Y_train_concat_ZM_S, X_test_concat_ZM, Y_test_concat_ZM, tsf_model, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "86bfaba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_results(tsf_concat_S, \"TSF_GNI_WithoutC_Concatenation_Results\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f83624f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(87245, 1440): TSF Classifier is Done! \n",
      "\n"
     ]
    }
   ],
   "source": [
    "tsf_concat_A = kfold_training('TSF', X_train_concat_ZM_A, Y_train_concat_ZM_A, X_test_concat_ZM, Y_test_concat_ZM, tsf_model, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "325b9f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_results(tsf_concat_A, \"TSF_TimeGAN_WithoutC_Concatenation_Results\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f90d5e67",
   "metadata": {},
   "source": [
    "## 2D to 3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ba8c56e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def the_2dto3d(X_train):\n",
    "    num_attributes = 24\n",
    "    num_partitions = 5\n",
    "    num_timestamps = 60\n",
    "    X_train_concat_ZM_3D = []\n",
    "    for i in range(0, num_partitions):\n",
    "        new_3D = np.zeros((X_train[i].shape[0], num_timestamps, num_attributes))\n",
    "\n",
    "        for j in range(0, X_train[i].shape[0]):\n",
    "            for m in range(0, num_attributes):\n",
    "                new_3D[j,:,m] = X_train[i][j,m*num_timestamps:(m+1)*num_timestamps]\n",
    "        X_train_concat_ZM_3D.append(new_3D)\n",
    "    return X_train_concat_ZM_3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "25643957",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_concat_ZM_RTS_3D = the_2dto3d(X_train_concat_ZM_RTS)\n",
    "X_train_concat_ZM_RTA_3D = the_2dto3d(X_train_concat_ZM_RTA)\n",
    "del X_train_concat_ZM_RTS\n",
    "del X_train_concat_ZM_RTA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "570ba9f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_concat_ZM_3D = the_2dto3d(X_test_concat_ZM)\n",
    "del X_test_concat_ZM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ee4f4ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_concat_ZM_S_3D = the_2dto3d(X_train_concat_ZM_S)\n",
    "X_train_concat_ZM_A_3D = the_2dto3d(X_train_concat_ZM_A)\n",
    "del X_train_concat_ZM_S\n",
    "del X_train_concat_ZM_A"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e814653",
   "metadata": {},
   "source": [
    "### LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfbf7110",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSTM Concatenation\n",
    "lstm_concat_RTS = kfold_training('LSTM', X_train_concat_ZM_RTS_3D, Y_train_concat_ZM_RTS, X_test_concat_ZM_3D, Y_test_concat_ZM, lstm_model, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "556a91a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_results(lstm_concat_RTS, \"LSTM_RusTomekGNI_WithoutC_Concatenation_Results\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "825c966e",
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_concat_RTA = kfold_training('LSTM', X_train_concat_ZM_RTA_3D, Y_train_concat_ZM_RTA, X_test_concat_ZM_3D, Y_test_concat_ZM, lstm_model, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95caa983",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_results(lstm_concat_RTA, \"LSTM_RusTomekTimeGAN_WithoutC_Concatenation_Results\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54737735",
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_concat_S = kfold_training('LSTM', X_train_concat_ZM_S_3D, Y_train_concat_ZM_S, X_test_concat_ZM_3D, Y_test_concat_ZM, lstm_model, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da6e53b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_results(lstm_concat_S, \"LSTM_GNI_WithoutC_Concatenation_Results\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44495efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_concat_A = kfold_training('LSTM', X_train_concat_ZM_A_3D, Y_train_concat_ZM_A, X_test_concat_ZM_3D, Y_test_concat_ZM, lstm_model, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb3431e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_results(lstm_concat_A, \"LSTM_TimeGAN_WithoutC_Concatenation_Results\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cba990f3",
   "metadata": {},
   "source": [
    "### 1D-CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95bd7e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_concat_RTS = kfold_training('1DCNN', X_train_concat_ZM_RTS_3D, Y_train_concat_ZM_RTS, X_test_concat_ZM_3D, Y_test_concat_ZM, cnn_model, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81b80bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_results(cnn_concat_RTS, \"1DCNN_RusTomekGNI_WithoutC_Concatenation_Results\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7e6ae32",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_concat_RTA = kfold_training('1DCNN', X_train_concat_ZM_RTA_3D, Y_train_concat_ZM_RTA, X_test_concat_ZM_3D, Y_test_concat_ZM, cnn_model, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fe620ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_results(cnn_concat_RTA, \"1DCNN_RusTomekTimeGAN_WithoutC_Concatenation_Results\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2f25369",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_concat_S = kfold_training('1DCNN', X_train_concat_ZM_S_3D, Y_train_concat_ZM_S, X_test_concat_ZM_3D, Y_test_concat_ZM, cnn_model, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "136a17eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_results(cnn_concat_S, \"1DCNN_GNI_WithoutC_Concatenation_Results\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4776beaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_concat_A = kfold_training('1DCNN', X_train_concat_ZM_A_3D, Y_train_concat_ZM_A, X_test_concat_ZM_3D, Y_test_concat_ZM, cnn_model, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "098bc9e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_results(cnn_concat_A, \"1DCNN_TimeGAN_WithoutC_Concatenation_Results\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bd7cde9",
   "metadata": {},
   "source": [
    "### RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a8922bad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2356/2356 [==============================] - 4s 2ms/step\n",
      "(20000, 60, 24): RNN Classifier is Done! \n",
      "\n",
      "2356/2356 [==============================] - 4s 2ms/step\n",
      "(20000, 60, 24): RNN Classifier is Done! \n",
      "\n"
     ]
    }
   ],
   "source": [
    "rnn_concat_RTS = kfold_training('RNN', X_train_concat_ZM_RTS_3D, Y_train_concat_ZM_RTS, X_test_concat_ZM_3D, Y_test_concat_ZM, rnn_model, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cd386aba",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_results(rnn_concat_RTS, \"RNN_RusTomekGNI_WithoutC_Concatenation_Results\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5ca92d3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2356/2356 [==============================] - 4s 2ms/step\n",
      "(19320, 60, 24): RNN Classifier is Done! \n",
      "\n",
      "2356/2356 [==============================] - 4s 2ms/step\n",
      "(19320, 60, 24): RNN Classifier is Done! \n",
      "\n",
      "2356/2356 [==============================] - 4s 2ms/step\n",
      "(19320, 60, 24): RNN Classifier is Done! \n",
      "\n",
      "2356/2356 [==============================] - 4s 2ms/step\n",
      "(19320, 60, 24): RNN Classifier is Done! \n",
      "\n",
      "2356/2356 [==============================] - 4s 2ms/step\n",
      "(19320, 60, 24): RNN Classifier is Done! \n",
      "\n",
      "2356/2356 [==============================] - 4s 2ms/step\n",
      "(19320, 60, 24): RNN Classifier is Done! \n",
      "\n",
      "2356/2356 [==============================] - 4s 2ms/step\n",
      "(19320, 60, 24): RNN Classifier is Done! \n",
      "\n",
      "2356/2356 [==============================] - 4s 1ms/step\n",
      "(19320, 60, 24): RNN Classifier is Done! \n",
      "\n",
      "2356/2356 [==============================] - 4s 2ms/step\n",
      "(19320, 60, 24): RNN Classifier is Done! \n",
      "\n",
      "2356/2356 [==============================] - 4s 2ms/step\n",
      "(19320, 60, 24): RNN Classifier is Done! \n",
      "\n",
      "2356/2356 [==============================] - 4s 1ms/step\n",
      "(19320, 60, 24): RNN Classifier is Done! \n",
      "\n",
      "2356/2356 [==============================] - 4s 2ms/step\n",
      "(19320, 60, 24): RNN Classifier is Done! \n",
      "\n",
      "2356/2356 [==============================] - 4s 2ms/step\n",
      "(19320, 60, 24): RNN Classifier is Done! \n",
      "\n",
      "2356/2356 [==============================] - 4s 1ms/step\n",
      "(19320, 60, 24): RNN Classifier is Done! \n",
      "\n",
      "2356/2356 [==============================] - 4s 2ms/step\n",
      "(19320, 60, 24): RNN Classifier is Done! \n",
      "\n",
      "2356/2356 [==============================] - 4s 1ms/step\n",
      "(19320, 60, 24): RNN Classifier is Done! \n",
      "\n",
      "2356/2356 [==============================] - 4s 2ms/step\n",
      "(19320, 60, 24): RNN Classifier is Done! \n",
      "\n",
      "2356/2356 [==============================] - 3s 1ms/step\n",
      "(19320, 60, 24): RNN Classifier is Done! \n",
      "\n"
     ]
    }
   ],
   "source": [
    "rnn_concat_RTA = kfold_training('RNN', X_train_concat_ZM_RTA_3D, Y_train_concat_ZM_RTA, X_test_concat_ZM_3D, Y_test_concat_ZM, rnn_model, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2979fd5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_results(rnn_concat_RTA, \"RNN_RusTomekTimeGAN_WithoutC_Concatenation_Results\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a199a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_concat_S = kfold_training('RNN', X_train_concat_ZM_S_3D, Y_train_concat_ZM_S, X_test_concat_ZM_3D, Y_test_concat_ZM, rnn_model, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25a5c8a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_results(rnn_concat_S, \"RNN_GNI_WithoutC_Concatenation_Results\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "181676a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_concat_A = kfold_training('RNN', X_train_concat_ZM_A_3D, Y_train_concat_ZM_A, X_test_concat_ZM_3D, Y_test_concat_ZM, rnn_model, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1718475d",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_results(rnn_concat_A, \"RNN_TimeGAN_WithoutC_Concatenation_Results\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b00618b5",
   "metadata": {},
   "source": [
    "### GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "98bba36a",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m gru_concat_RTS \u001b[38;5;241m=\u001b[39m kfold_training(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGRU\u001b[39m\u001b[38;5;124m'\u001b[39m, X_train_concat_ZM_RTS_3D, Y_train_concat_ZM_RTS, X_test_concat_ZM_3D, Y_test_concat_ZM, gru_model, \u001b[38;5;241m1\u001b[39m)\n",
      "Cell \u001b[0;32mIn[5], line 9\u001b[0m, in \u001b[0;36mkfold_training\u001b[0;34m(name, X_train, Y_train, X_test, Y_test, training_func, num)\u001b[0m\n\u001b[1;32m      7\u001b[0m train_index \u001b[38;5;241m=\u001b[39m kfold[i,\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m      8\u001b[0m test_index \u001b[38;5;241m=\u001b[39m kfold[i,\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m----> 9\u001b[0m metrics_values \u001b[38;5;241m=\u001b[39m training_func(X_train[train_index\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m], Y_train[train_index\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m], X_test[test_index\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m], Y_test[test_index\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m (metrics_values[\u001b[38;5;241m4\u001b[39m]\u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0.6\u001b[39m):\n\u001b[1;32m     11\u001b[0m     metrics_values \u001b[38;5;241m=\u001b[39m training_func(X_train[train_index\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m], Y_train[train_index\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m], X_test[test_index\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m], Y_test[test_index\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\n",
      "Cell \u001b[0;32mIn[11], line 26\u001b[0m, in \u001b[0;36mgru_model\u001b[0;34m(X_train, Y_train, X_test, Y_test)\u001b[0m\n\u001b[1;32m     23\u001b[0m model\u001b[38;5;241m.\u001b[39madd(Dense(\u001b[38;5;241m1\u001b[39m, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msigmoid\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[1;32m     24\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbinary_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m, optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m, metrics\u001b[38;5;241m=\u001b[39mkeras\u001b[38;5;241m.\u001b[39mmetrics\u001b[38;5;241m.\u001b[39mPrecisionAtRecall(\u001b[38;5;241m0.90\u001b[39m))\n\u001b[0;32m---> 26\u001b[0m model\u001b[38;5;241m.\u001b[39mfit(X_train, Y_train, epochs\u001b[38;5;241m=\u001b[39mepochs, batch_size\u001b[38;5;241m=\u001b[39mbatch_size, verbose\u001b[38;5;241m=\u001b[39mverbose)\n\u001b[1;32m     28\u001b[0m best_threshold \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[1;32m     29\u001b[0m best_tss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/keras/src/engine/training.py:1783\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1775\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1776\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1777\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1780\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m   1781\u001b[0m ):\n\u001b[1;32m   1782\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1783\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_function(iterator)\n\u001b[1;32m   1784\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1785\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:831\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    828\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    830\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 831\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m    833\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    834\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:867\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    864\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    865\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    866\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 867\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m tracing_compilation\u001b[38;5;241m.\u001b[39mcall_function(\n\u001b[1;32m    868\u001b[0m       args, kwds, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_no_variable_creation_config\n\u001b[1;32m    869\u001b[0m   )\n\u001b[1;32m    870\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    871\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    872\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    873\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[0;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m function\u001b[38;5;241m.\u001b[39m_call_flat(  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    140\u001b[0m     flat_inputs, captured_inputs\u001b[38;5;241m=\u001b[39mfunction\u001b[38;5;241m.\u001b[39mcaptured_inputs\n\u001b[1;32m    141\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1264\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1260\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1261\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1262\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1263\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1264\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inference_function\u001b[38;5;241m.\u001b[39mflat_call(args)\n\u001b[1;32m   1265\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1266\u001b[0m     args,\n\u001b[1;32m   1267\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1268\u001b[0m     executing_eagerly)\n\u001b[1;32m   1269\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:217\u001b[0m, in \u001b[0;36mAtomicFunction.flat_call\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mflat_call\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    216\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 217\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m(\u001b[38;5;241m*\u001b[39margs)\n\u001b[1;32m    218\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:252\u001b[0m, in \u001b[0;36mAtomicFunction.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    250\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[1;32m    251\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 252\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mcall_function(\n\u001b[1;32m    253\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname,\n\u001b[1;32m    254\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[1;32m    255\u001b[0m         \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mflat_outputs),\n\u001b[1;32m    256\u001b[0m     )\n\u001b[1;32m    257\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    258\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[1;32m    259\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    260\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[1;32m    261\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[1;32m    262\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/eager/context.py:1479\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1477\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[1;32m   1478\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1479\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute(\n\u001b[1;32m   1480\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1481\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[1;32m   1482\u001b[0m       inputs\u001b[38;5;241m=\u001b[39mtensor_inputs,\n\u001b[1;32m   1483\u001b[0m       attrs\u001b[38;5;241m=\u001b[39mattrs,\n\u001b[1;32m   1484\u001b[0m       ctx\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1485\u001b[0m   )\n\u001b[1;32m   1486\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1487\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1488\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1489\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1493\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[1;32m   1494\u001b[0m   )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/eager/execute.py:60\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     53\u001b[0m   \u001b[38;5;66;03m# Convert any objects of type core_types.Tensor to Tensor.\u001b[39;00m\n\u001b[1;32m     54\u001b[0m   inputs \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     55\u001b[0m       tensor_conversion_registry\u001b[38;5;241m.\u001b[39mconvert(t)\n\u001b[1;32m     56\u001b[0m       \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(t, core_types\u001b[38;5;241m.\u001b[39mTensor)\n\u001b[1;32m     57\u001b[0m       \u001b[38;5;28;01melse\u001b[39;00m t\n\u001b[1;32m     58\u001b[0m       \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m inputs\n\u001b[1;32m     59\u001b[0m   ]\n\u001b[0;32m---> 60\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[1;32m     61\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     63\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "gru_concat_RTS = kfold_training('GRU', X_train_concat_ZM_RTS_3D, Y_train_concat_ZM_RTS, X_test_concat_ZM_3D, Y_test_concat_ZM, gru_model, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6bc4f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_results(gru_concat_RTS, \"GRU_RusTomekGNI_WithoutC_Concatenation_Results\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f033da76",
   "metadata": {},
   "outputs": [],
   "source": [
    "gru_concat_RTA = kfold_training('GRU', X_train_concat_ZM_RTA_3D, Y_train_concat_ZM_RTA, X_test_concat_ZM_3D, Y_test_concat_ZM, gru_model, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab46dc19",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_results(gru_concat_RTA, \"GRU_RusTomekTimeGAN_WithoutC_Concatenation_Results\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23441ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "gru_concat_S = kfold_training('GRU', X_train_concat_ZM_S_3D, Y_train_concat_ZM_S, X_test_concat_ZM_3D, Y_test_concat_ZM, gru_model, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5120e055",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_results(gru_concat_S, \"GRU_GNI_WithoutC_Concatenation_Results\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcde897f",
   "metadata": {},
   "outputs": [],
   "source": [
    "gru_concat_A = kfold_training('GRU', X_train_concat_ZM_A_3D, Y_train_concat_ZM_A, X_test_concat_ZM_3D, Y_test_concat_ZM, gru_model, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa4a3b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_results(gru_concat_A, \"GRU_TimeGAN_WithoutC_Concatenation_Results\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7c3686d",
   "metadata": {},
   "source": [
    "# Comparison "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a634b915",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "data_dir = \"/Users/samskanderi/Documents/Research_Project/SWANSF/code/results/\"\n",
    "model_name = ['LSTM','1DCNN','RNN','GRU']\n",
    "ousampling_name = ['RusTomekGNI','RusTomekTimeGAN','GNI','TimeGAN']\n",
    "\n",
    "values = np.array([])\n",
    "names = []\n",
    "count = 0\n",
    "for name in model_name:\n",
    "    for s_name in ousampling_name:\n",
    "        with open(data_dir + name + '_' + s_name + '_WithoutC_Concatenation_Results' + \".pkl\", 'rb') as f:\n",
    "            if count == 0:\n",
    "                values=np.array(pickle.load(f))\n",
    "            else:\n",
    "                values = np.append(values, np.array(pickle.load(f)), axis=0)\n",
    "            names.append( name+ ' (' + s_name + ')' )\n",
    "            count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4a5ac5bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_results(names, values, num):\n",
    "    train_test_counts = 1\n",
    "    np.printoptions(precision=4, suppress=True)\n",
    "    for i in range(0, int(values.shape[0]/num)):\n",
    "        print(\"P_Train = \"+ str(values[i,0]) + \" & \" + \"P_Test = \" + str(values[i,1]))\n",
    "        for j in range(0, num):\n",
    "            print(names[j] + ' :' +  ' TP={:.0f}'.format(values[j*train_test_counts+i,2]) + ' FN={:.0f}'.format(values[j*train_test_counts+i,3]) + ' FP={:.0f}'.format(values[j*train_test_counts+i,4])\n",
    "                 + ' TN={:.0f}'.format(values[j*train_test_counts+i,5]) + ' TSS={:.3f}'.format(values[j*train_test_counts+i,6]) + ' HSS1={:.3f}'.format(values[j*train_test_counts+i,7]) + ' HSS2={:.3f}'.format(values[j*train_test_counts+i,8])\n",
    "                 + ' GSS={:.3f}'.format(values[j*train_test_counts+i,9]) + ' Recall={:.3f}'.format(values[j*train_test_counts+i,10]) + ' Precision={:.3f}'.format(values[j*train_test_counts+i,11]))\n",
    "        print('\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6926a2de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P_Train = 4.0 & P_Test = 5.0\n",
      "LSTM (RusTomekGNI) : TP=990 FN=0 FP=74375 TN=0 TSS=0.000 HSS1=0.000 HSS2=0.000 GSS=0.000 Recall=1.000 Precision=0.987\n",
      "LSTM (RusTomekTimeGAN) : TP=990 FN=0 FP=72154 TN=2221 TSS=0.030 HSS1=0.001 HSS2=0.019 GSS=29.175 Recall=1.000 Precision=0.986\n",
      "LSTM (GNI) : TP=990 FN=0 FP=74372 TN=3 TSS=0.000 HSS1=0.000 HSS2=0.000 GSS=0.039 Recall=1.000 Precision=0.987\n",
      "LSTM (TimeGAN) : TP=987 FN=3 FP=17342 TN=57033 TSS=0.764 HSS1=0.079 HSS2=0.101 GSS=746.229 Recall=0.997 Precision=0.946\n",
      "1DCNN (RusTomekGNI) : TP=990 FN=0 FP=74375 TN=0 TSS=0.000 HSS1=0.000 HSS2=0.000 GSS=0.000 Recall=1.000 Precision=0.987\n",
      "1DCNN (RusTomekTimeGAN) : TP=990 FN=0 FP=72457 TN=1918 TSS=0.026 HSS1=0.001 HSS2=0.018 GSS=25.195 Recall=1.000 Precision=0.987\n",
      "1DCNN (GNI) : TP=990 FN=0 FP=74375 TN=0 TSS=0.000 HSS1=0.000 HSS2=0.000 GSS=0.000 Recall=1.000 Precision=0.987\n",
      "1DCNN (TimeGAN) : TP=990 FN=0 FP=56264 TN=18111 TSS=0.244 HSS1=0.008 HSS2=0.032 GSS=237.907 Recall=1.000 Precision=0.983\n",
      "RNN (RusTomekGNI) : TP=969 FN=21 FP=9180 TN=65195 TSS=0.855 HSS1=0.154 HSS2=0.171 GSS=835.682 Recall=0.979 Precision=0.095\n",
      "RNN (RusTomekTimeGAN) : TP=847 FN=143 FP=14750 TN=59625 TSS=0.657 HSS1=0.079 HSS2=0.096 GSS=642.117 Recall=0.856 Precision=0.054\n",
      "RNN (GNI) : TP=990 FN=0 FP=72739 TN=1636 TSS=0.022 HSS1=0.001 HSS2=0.017 GSS=21.491 Recall=1.000 Precision=0.987\n",
      "RNN (TimeGAN) : TP=990 FN=0 FP=65873 TN=8502 TSS=0.114 HSS1=0.003 HSS2=0.026 GSS=111.683 Recall=1.000 Precision=0.985\n",
      "GRU (RusTomekGNI) : TP=9288 FN=709 FP=433 TN=9564 TSS=0.886 HSS1=0.886 HSS2=0.886 GSS=4427.500 Recall=0.929 Precision=0.955\n",
      "GRU (RusTomekTimeGAN) : TP=906 FN=84 FP=7086 TN=67289 TSS=0.820 HSS1=0.183 HSS2=0.197 GSS=801.017 Recall=0.915 Precision=0.887\n",
      "GRU (GNI) : TP=990 FN=0 FP=74281 TN=94 TSS=0.001 HSS1=0.000 HSS2=0.002 GSS=1.235 Recall=1.000 Precision=0.987\n",
      "GRU (TimeGAN) : TP=990 FN=0 FP=31807 TN=42568 TSS=0.572 HSS1=0.034 HSS2=0.057 GSS=559.176 Recall=1.000 Precision=0.970\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "compare_results(names, values, 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c600f8e3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
