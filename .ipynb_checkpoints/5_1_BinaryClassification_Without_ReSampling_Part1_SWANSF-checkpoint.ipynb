{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b42f5d50",
   "metadata": {},
   "source": [
    "# SVM - MLPClassifier - Complement Naive Bayes  - Randon Forest on NewFeatures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5d323d1",
   "metadata": {},
   "source": [
    "# Train Test Split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d29e199",
   "metadata": {},
   "source": [
    "## Stratified Cross validation (k = 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c37f292",
   "metadata": {},
   "source": [
    "P1 Train and P2 Test, P1 Train and P3 Test, P1 Train and P4 Test, P1 Train and P5 Test\n",
    "P2 Train and P3 Test, P2 Train and P4 Test, P2 Train and P5 Test\n",
    "P3 Train and P4 Test, P3 Train and P5 Test\n",
    "P4 Train and P5 Test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "529fa14d",
   "metadata": {},
   "source": [
    "# Evaluation Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "255d0498",
   "metadata": {},
   "outputs": [],
   "source": [
    "# float(\"{:.2f}\".format(13.949999999999999))\n",
    "\n",
    "def TSS(TP,TN,FP,FN):\n",
    "    TSS_value = (TP / (TP + FN)) - (FP / (FP + TN))\n",
    "    return TSS_value\n",
    "\n",
    "def HSS1(TP,TN,FP,FN):\n",
    "    HSS1_value = (2 * (TP * TN - FP * FN)) / ((TP + FN) * (FN + TN) + (TP + FP) * (FP + TN))\n",
    "    return HSS1_value\n",
    "    \n",
    "def HSS2(TP,TN,FP,FN):\n",
    "    HSS2_value = (2 * (TP * TN - FP * FN)) / ((TP + FP) * (FN + TN) + (TP + FN) * (FP + TN))\n",
    "    return HSS2_value\n",
    "\n",
    "def GSS(TP,TN,FP,FN):\n",
    "    GSS_value = (TP - (TP + FP) * (TP + FN) / (TP + FP + FN + TN))\n",
    "    return GSS_value\n",
    "\n",
    "def Recall(TP,TN,FP,FN):\n",
    "    Recall_value = (TP) / (TP + FN)\n",
    "    return Recall_value\n",
    "\n",
    "def FPR(TP,TN,FP,FN):\n",
    "    fpr_value = (FP) / (FP + TN)\n",
    "    return fpr_value\n",
    "\n",
    "def Accuracy(TP,TN,FP,FN):\n",
    "    accuracy_value = (TP + TN) / (TP + TN + FP + FN)\n",
    "    return accuracy_value\n",
    "\n",
    "def Precision(TP,TN,FP,FN):\n",
    "    precision_value = (TP) / (TP + FP)\n",
    "    return precision_value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd0d872d",
   "metadata": {},
   "source": [
    "# Loading the Final Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9516c63",
   "metadata": {},
   "source": [
    "## New Features "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "534e436f",
   "metadata": {},
   "source": [
    "### LSBZM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ebdc0e3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P1 Nan-Value: False\n",
      "P2 Nan-Value: False\n",
      "P3 Nan-Value: False\n",
      "P4 Nan-Value: False\n",
      "P5 Nan-Value: False\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "data_dir = \"/Users/samskanderi/Documents/Research_Project/SWANSF/code/5_2_FinalData_NewFeatures_LSBZM_KnnImputation/\"\n",
    "X_train_NewF_LSBZM = []\n",
    "Y_train_NewF_LSBZM = []\n",
    "\n",
    "\n",
    "num_partitions = 5\n",
    "\n",
    "for i in range(0,num_partitions):\n",
    "    with open(data_dir + \"Partition\" + str(i+1) + \"_NewFeatures_LSBZM_KnnImputation\" + \".pkl\", 'rb') as f:\n",
    "        X_train_NewF_LSBZM.append(pickle.load(f))\n",
    "    print(\"P\"+str(i+1)+\" Nan-Value: \"+ str(np.isnan(X_train_NewF_LSBZM[i]).any() or np.isinf(X_train_NewF_LSBZM[i]).any()))\n",
    "    \n",
    "    with open(data_dir + \"Partition\" + str(i+1) + \"_Labels_NewFeatures_LSBZM_KnnImputation\" + \".pkl\", 'rb') as f:\n",
    "        Y_train_NewF_LSBZM.append(pickle.load(f))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cfc250b",
   "metadata": {},
   "source": [
    "## MeanImputation, MinMaxNorm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6ae802f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P1 Nan-Value: False\n",
      "P2 Nan-Value: False\n",
      "P3 Nan-Value: False\n",
      "P4 Nan-Value: False\n",
      "P5 Nan-Value: False\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "data_dir = \"/Users/samskanderi/Documents/Research_Project/SWANSF/code/5_0_FinalData_ZM_BaseLineImputation/\"\n",
    "X_train_NewF_M = []\n",
    "Y_train_NewF_M = []\n",
    "\n",
    "\n",
    "num_partitions = 5\n",
    "\n",
    "for i in range(0,num_partitions):\n",
    "    with open(data_dir + \"Partition\" + str(i+1) + \"_NewFeatures_MinMaxNorm_MeanImputation\" + \".pkl\", 'rb') as f:\n",
    "        X_train_NewF_M.append(pickle.load(f))\n",
    "    print(\"P\"+str(i+1)+\" Nan-Value: \"+ str(np.isnan(X_train_NewF_M[i]).any() or np.isinf(X_train_NewF_M[i]).any()))\n",
    "    \n",
    "    with open(data_dir + \"Partition\" + str(i+1) + \"_Labels_NewFeatures_MinMaxNorm_MeanImputation\" + \".pkl\", 'rb') as f:\n",
    "        Y_train_NewF_M.append(pickle.load(f))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93a9918f",
   "metadata": {},
   "source": [
    "## MeanImputation, ZscoreNorm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3cccddb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P1 Nan-Value: False\n",
      "P2 Nan-Value: False\n",
      "P3 Nan-Value: False\n",
      "P4 Nan-Value: False\n",
      "P5 Nan-Value: False\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "data_dir = \"/Users/samskanderi/Documents/Research_Project/SWANSF/code/5_0_FinalData_ZM_BaseLineImputation/\"\n",
    "X_train_NewF_Z = []\n",
    "Y_train_NewF_Z = []\n",
    "\n",
    "\n",
    "num_partitions = 5\n",
    "\n",
    "for i in range(0,num_partitions):\n",
    "    with open(data_dir + \"Partition\" + str(i+1) + \"_NewFeatures_ZNorm_MeanImputation\" + \".pkl\", 'rb') as f:\n",
    "        X_train_NewF_Z.append(pickle.load(f))\n",
    "    print(\"P\"+str(i+1)+\" Nan-Value: \"+ str(np.isnan(X_train_NewF_Z[i]).any() or np.isinf(X_train_NewF_Z[i]).any()))\n",
    "    \n",
    "    with open(data_dir + \"Partition\" + str(i+1) + \"_Labels_NewFeatures_ZNorm_MeanImputation\" + \".pkl\", 'rb') as f:\n",
    "        Y_train_NewF_Z.append(pickle.load(f))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09248daa",
   "metadata": {},
   "source": [
    "## NextvalueImputation, MinMaxNorm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "72aad456",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P1 Nan-Value: False\n",
      "P2 Nan-Value: False\n",
      "P3 Nan-Value: False\n",
      "P4 Nan-Value: False\n",
      "P5 Nan-Value: False\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "data_dir = \"/Users/samskanderi/Documents/Research_Project/SWANSF/code/5_0_FinalData_ZM_BaseLineImputation/\"\n",
    "X_train_NewF_M_N = []\n",
    "Y_train_NewF_M_N = []\n",
    "\n",
    "\n",
    "num_partitions = 5\n",
    "\n",
    "for i in range(0,num_partitions):\n",
    "    with open(data_dir + \"Partition\" + str(i+1) + \"_NewFeatures_MinMaxNorm_NextvalueImputation\" + \".pkl\", 'rb') as f:\n",
    "        X_train_NewF_M_N.append(pickle.load(f))\n",
    "    print(\"P\"+str(i+1)+\" Nan-Value: \"+ str(np.isnan(X_train_NewF_M_N[i]).any() or np.isinf(X_train_NewF_M_N[i]).any()))\n",
    "    \n",
    "    with open(data_dir + \"Partition\" + str(i+1) + \"_Labels_NewFeatures_MinMaxNorm_NextvalueImputation\" + \".pkl\", 'rb') as f:\n",
    "        Y_train_NewF_M_N.append(pickle.load(f))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7451b5f7",
   "metadata": {},
   "source": [
    "## NextvalueImputation, ZscoreNorm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "03cdf64a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P1 Nan-Value: False\n",
      "P2 Nan-Value: False\n",
      "P3 Nan-Value: False\n",
      "P4 Nan-Value: False\n",
      "P5 Nan-Value: False\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "data_dir = \"/Users/samskanderi/Documents/Research_Project/SWANSF/code/5_0_FinalData_ZM_BaseLineImputation/\"\n",
    "X_train_NewF_Z_N = []\n",
    "Y_train_NewF_Z_N = []\n",
    "\n",
    "\n",
    "num_partitions = 5\n",
    "\n",
    "for i in range(0,num_partitions):\n",
    "    with open(data_dir + \"Partition\" + str(i+1) + \"_NewFeatures_ZNorm_NextvalueImputation\" + \".pkl\", 'rb') as f:\n",
    "        X_train_NewF_Z_N.append(pickle.load(f))\n",
    "    print(\"P\"+str(i+1)+\" Nan-Value: \"+ str(np.isnan(X_train_NewF_Z_N[i]).any() or np.isinf(X_train_NewF_Z_N[i]).any()))\n",
    "    \n",
    "    with open(data_dir + \"Partition\" + str(i+1) + \"_Labels_NewFeatures_ZNorm_NextvalueImputation\" + \".pkl\", 'rb') as f:\n",
    "        Y_train_NewF_Z_N.append(pickle.load(f))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d520699a",
   "metadata": {},
   "source": [
    "# Useful Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ed6ceb4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kfold_training(name, X_train, Y_train, training_func, num, rocket_kernels= 1500, tsf_estimator=25):\n",
    "    #kfold = np.array([[1,2],[1,3],[1,4],[1,5],[2,3],[2,4],[2,5],[3,4],[3,5],[4,5]])\n",
    "    kfold = np.array([[1,2],[2,3],[3,4],[4,5]])\n",
    "\n",
    "    metrics = []\n",
    "    metrics_values = np.array([])\n",
    "    \n",
    "    for i in range(0, num):\n",
    "        train_index = kfold[i,0]\n",
    "        test_index = kfold[i,1]\n",
    "        metrics_values = training_func(X_train[train_index-1], Y_train[train_index-1], X_train[test_index-1], Y_train[test_index-1])\n",
    "        count = 0\n",
    "        while (metrics_values[0] == 0):\n",
    "            count += 1\n",
    "            metrics_values = training_func(X_train[train_index-1], Y_train[train_index-1], X_train[test_index-1], Y_train[test_index-1])\n",
    "            if count == 5:\n",
    "                break\n",
    "        \n",
    "        metrics.append(np.append(np.append(train_index, test_index), metrics_values))\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faf5130c",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10454d6f",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9a1291ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def svm_model(X_train, Y_train, X_test, Y_test):\n",
    "    \n",
    "    data_dir = \"/Users/samskanderi/Documents/Research_Project/SWANSF/code/models/\"\n",
    "\n",
    "\n",
    "    # Create an SVM classifier (you can choose different kernels like 'linear', 'rbf', etc.)\n",
    "    svm_classifier = SVC(kernel='rbf', C=1.0)\n",
    "    svm_classifier.fit(X_train, Y_train)\n",
    "    y_pred = svm_classifier.predict(X_test)\n",
    "    \n",
    "    \n",
    "    print(str(X_train.shape)+': SVM Classifier is Done! \\n')\n",
    "    \n",
    "\n",
    "    confusion = confusion_matrix(Y_test, y_pred)\n",
    "    tn, fp, fn, tp = confusion.ravel()\n",
    "\n",
    "    tss = TSS(tp,tn,fp,fn)\n",
    "    hss1 = HSS1(tp,tn,fp,fn)\n",
    "    hss2 = HSS2(tp,tn,fp,fn)\n",
    "    gss = GSS(tp,tn,fp,fn)\n",
    "    recall = Recall(tp,tn,fp,fn)\n",
    "    precision = Precision(tp,tn,fp,fn)\n",
    "    \n",
    "    output_values = np.array([tp, fn, fp, tn, tss, hss1, hss2, gss, recall, precision])\n",
    "\n",
    "\n",
    "    #joblib.dump(classifier, data_dir + \"svm_model.pkl\")\n",
    "\n",
    "    #loaded_svm_model = joblib.load(data_dir + \"svm_model.pkl\")\n",
    "    \n",
    "    return output_values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12a9a3ae",
   "metadata": {},
   "source": [
    "## MLPClassifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a780f706",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def mlp_model(X_train, Y_train, X_test, Y_test):\n",
    "    \n",
    "    data_dir = \"/Users/samskanderi/Documents/Research_Project/SWANSF/code/models/\"\n",
    "\n",
    "    # Define the MLP model\n",
    "    # Define the MLP model with four hidden layers\n",
    "    model = keras.Sequential([\n",
    "        layers.Input(shape=(216,)),  # Input layer with 216 features\n",
    "        layers.Dense(64, activation='relu'),  # Hidden layer with 64 units and ReLU activation\n",
    "        layers.Dense(32, activation='relu'),  # Hidden layer with 32 units and ReLU activation\n",
    "        layers.Dense(16, activation='relu'),  # Hidden layer with 16 units and ReLU activation\n",
    "        layers.Dense(8, activation='relu'),  # Hidden layer with 16 units and ReLU activation\n",
    "        layers.Dense(1, activation='sigmoid')  # Output layer with 1 unit and sigmoid activation (binary classification)\n",
    "    ])\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=keras.metrics.PrecisionAtRecall(0.95))\n",
    "\n",
    "    # Train the model\n",
    "    model.fit(X_train, Y_train, epochs=15, batch_size=32, verbose=0)  # Adjust epochs and batch_size as needed\n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "    threshold = 0.5  # Adjust the threshold as needed\n",
    "    y_pred_binary = (y_pred > threshold).astype(int)\n",
    "    \n",
    "    print(str(X_train.shape)+': MLP Classifier is Done! \\n')\n",
    "\n",
    "\n",
    "    confusion = confusion_matrix(Y_test, y_pred_binary)\n",
    "    tn, fp, fn, tp = confusion.ravel()\n",
    "\n",
    "    tss = TSS(tp,tn,fp,fn)\n",
    "    hss1 = HSS1(tp,tn,fp,fn)\n",
    "    hss2 = HSS2(tp,tn,fp,fn)\n",
    "    gss = GSS(tp,tn,fp,fn)\n",
    "    recall = Recall(tp,tn,fp,fn)\n",
    "    precision = Precision(tp,tn,fp,fn)\n",
    "    \n",
    "    output_values = np.array([tp, fn, fp, tn, tss, hss1, hss2, gss, recall, precision])\n",
    "\n",
    "\n",
    "    #joblib.dump(classifier, data_dir + \"mlp_model.pkl\")\n",
    "\n",
    "    #loaded_mlp_model = joblib.load(data_dir + \"mlp_model.pkl\")\n",
    "    \n",
    "    return output_values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d6b8014",
   "metadata": {},
   "source": [
    "# K Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "994a30d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def knn_model(X_train, Y_train, X_test, Y_test):\n",
    "    \n",
    "    data_dir = \"/Users/samskanderi/Documents/Research_Project/SWANSF/code/models/\"\n",
    "\n",
    "    # Create a Gaussian Naive Bayes classifier\n",
    "    nb_classifier = KNeighborsClassifier(n_neighbors=10)\n",
    "    nb_classifier.fit(X_train, Y_train)\n",
    "    y_pred = nb_classifier.predict(X_test)\n",
    "    \n",
    "    print(str(X_train.shape) + ': KNeighborsClassifier Classifier is Done! \\n')\n",
    "\n",
    "    confusion = confusion_matrix(Y_test, y_pred)\n",
    "    tn, fp, fn, tp = confusion.ravel()\n",
    "\n",
    "    tss = TSS(tp,tn,fp,fn)\n",
    "    hss1 = HSS1(tp,tn,fp,fn)\n",
    "    hss2 = HSS2(tp,tn,fp,fn)\n",
    "    gss = GSS(tp,tn,fp,fn)\n",
    "    recall = Recall(tp,tn,fp,fn)\n",
    "    precision = Precision(tp,tn,fp,fn)\n",
    "    \n",
    "    output_values = np.array([tp, fn, fp, tn, tss, hss1, hss2, gss, recall, precision])\n",
    "\n",
    "    #joblib.dump(nb_classifier, data_dir + \"naive_bayes_model.pkl\")\n",
    "\n",
    "    #loaded_nb_model = joblib.load(data_dir + \"naive_bayes_model.pkl\")\n",
    "\n",
    "    return output_values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cec60e3",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "55986975",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def random_forest_model(X_train, Y_train, X_test, Y_test):\n",
    "    \n",
    "    data_dir = \"/Users/samskanderi/Documents/Research_Project/SWANSF/code/models/\"\n",
    "\n",
    "    # Create a Random Forest classifier\n",
    "    # You can adjust 'n_estimators' and other parameters as needed\n",
    "    rf_classifier = RandomForestClassifier(n_estimators=60, random_state=42, criterion='entropy')\n",
    "    rf_classifier.fit(X_train, Y_train)\n",
    "    y_pred = rf_classifier.predict(X_test)\n",
    "    \n",
    "    print(str(X_train.shape) + ': Random Forest Classifier is Done! \\n')\n",
    "\n",
    "    confusion = confusion_matrix(Y_test, y_pred)\n",
    "    tn, fp, fn, tp = confusion.ravel()\n",
    "\n",
    "    tss = TSS(tp, tn, fp, fn)\n",
    "    hss1 = HSS1(tp, tn, fp, fn)\n",
    "    hss2 = HSS2(tp, tn, fp, fn)\n",
    "    gss = GSS(tp, tn, fp, fn)\n",
    "    recall = Recall(tp, tn, fp, fn)\n",
    "    precision = Precision(tp, tn, fp, fn)\n",
    "    \n",
    "    output_values = np.array([tp, fn, fp, tn, tss, hss1, hss2, gss, recall, precision])\n",
    "\n",
    "    #joblib.dump(rf_classifier, data_dir + \"random_forest_model.pkl\")\n",
    "\n",
    "    #loaded_rf_model = joblib.load(data_dir + \"random_forest_model.pkl\")\n",
    "\n",
    "    return output_values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32e9fd1e",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "127986e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_results(reslut, name):\n",
    "    data_dir = \"/Users/samskanderi/Documents/Research_Project/SWANSF/code/results/\"\n",
    "\n",
    "    with open(data_dir + name + \".pkl\", 'wb') as f:\n",
    "        pickle.dump(reslut, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c7bc689",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5b280418",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(73492, 216): SVM Classifier is Done! \n",
      "\n",
      "(88557, 216): SVM Classifier is Done! \n",
      "\n",
      "(42510, 216): SVM Classifier is Done! \n",
      "\n",
      "(51261, 216): SVM Classifier is Done! \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# SVM NewFeatures\n",
    "svm_newf = kfold_training('SVM', X_train_NewF_LSBZM, Y_train_NewF_LSBZM, svm_model, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a14a0c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_results(svm_newf, \"SVM_NewFeatures_Results\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dcda0440",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(73492, 216): SVM Classifier is Done! \n",
      "\n",
      "(88557, 216): SVM Classifier is Done! \n",
      "\n",
      "(42510, 216): SVM Classifier is Done! \n",
      "\n",
      "(51261, 216): SVM Classifier is Done! \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# SVM NewFeatures\n",
    "svm_newf = kfold_training('SVM', X_train_NewF_M, Y_train_NewF_M, svm_model, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "401da956",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_results(svm_newf, \"SVM_NewFeatures_MM_Results\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "89092ad6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(73492, 216): SVM Classifier is Done! \n",
      "\n",
      "(88557, 216): SVM Classifier is Done! \n",
      "\n",
      "(42510, 216): SVM Classifier is Done! \n",
      "\n",
      "(51261, 216): SVM Classifier is Done! \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# SVM NewFeatures\n",
    "svm_newf = kfold_training('SVM', X_train_NewF_Z, Y_train_NewF_Z, svm_model, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1e42b682",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_results(svm_newf, \"SVM_NewFeatures_ZM_Results\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c0cb7c52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(73492, 216): SVM Classifier is Done! \n",
      "\n",
      "(88557, 216): SVM Classifier is Done! \n",
      "\n",
      "(42510, 216): SVM Classifier is Done! \n",
      "\n",
      "(51261, 216): SVM Classifier is Done! \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# SVM NewFeatures\n",
    "svm_newf = kfold_training('SVM', X_train_NewF_M_N, Y_train_NewF_M_N, svm_model, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cba6dcf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_results(svm_newf, \"SVM_NewFeatures_MN_Results\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bf1fff87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(73492, 216): SVM Classifier is Done! \n",
      "\n",
      "(88557, 216): SVM Classifier is Done! \n",
      "\n",
      "(42510, 216): SVM Classifier is Done! \n",
      "\n",
      "(51261, 216): SVM Classifier is Done! \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# SVM NewFeatures\n",
    "svm_newf = kfold_training('SVM', X_train_NewF_Z_N, Y_train_NewF_Z_N, svm_model, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "04b12881",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_results(svm_newf, \"SVM_NewFeatures_ZN_Results\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5ce17de",
   "metadata": {},
   "source": [
    "## MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4dd95319",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2768/2768 [==============================] - 1s 329us/step\n",
      "(73492, 216): MLP Classifier is Done! \n",
      "\n",
      "1329/1329 [==============================] - 1s 331us/step\n",
      "(88557, 216): MLP Classifier is Done! \n",
      "\n",
      "1602/1602 [==============================] - 1s 389us/step\n",
      "(42510, 216): MLP Classifier is Done! \n",
      "\n",
      "2356/2356 [==============================] - 1s 406us/step\n",
      "(51261, 216): MLP Classifier is Done! \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# MLPClassifier NewFeatures\n",
    "mlp_newf = kfold_training('MLP', X_train_NewF_LSBZM, Y_train_NewF_LSBZM, mlp_model, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "097d194e",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_results(mlp_newf, \"MLPClassifier_NewFeatures_Results\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b0b0c80e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2768/2768 [==============================] - 1s 339us/step\n",
      "(73492, 216): MLP Classifier is Done! \n",
      "\n",
      "1329/1329 [==============================] - 0s 340us/step\n",
      "(88557, 216): MLP Classifier is Done! \n",
      "\n",
      "1602/1602 [==============================] - 1s 347us/step\n",
      "(42510, 216): MLP Classifier is Done! \n",
      "\n",
      "2356/2356 [==============================] - 1s 350us/step\n",
      "(51261, 216): MLP Classifier is Done! \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# MLPClassifier NewFeatures\n",
    "mlp_newf = kfold_training('MLP', X_train_NewF_M, Y_train_NewF_M, mlp_model, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "090bd126",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_results(mlp_newf, \"MLPClassifier_NewFeatures_MM_Results\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4f77f64e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2768/2768 [==============================] - 1s 386us/step\n",
      "(73492, 216): MLP Classifier is Done! \n",
      "\n",
      "1329/1329 [==============================] - 1s 367us/step\n",
      "(88557, 216): MLP Classifier is Done! \n",
      "\n",
      "1602/1602 [==============================] - 1s 358us/step\n",
      "(42510, 216): MLP Classifier is Done! \n",
      "\n",
      "2356/2356 [==============================] - 1s 354us/step\n",
      "(51261, 216): MLP Classifier is Done! \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# MLPClassifier NewFeatures\n",
    "mlp_newf = kfold_training('MLP', X_train_NewF_Z, Y_train_NewF_Z, mlp_model, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c84af6d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_results(mlp_newf, \"MLPClassifier_NewFeatures_ZM_Results\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7d528e3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2768/2768 [==============================] - 1s 368us/step\n",
      "(73492, 216): MLP Classifier is Done! \n",
      "\n",
      "1329/1329 [==============================] - 1s 370us/step\n",
      "(88557, 216): MLP Classifier is Done! \n",
      "\n",
      "1602/1602 [==============================] - 1s 367us/step\n",
      "(42510, 216): MLP Classifier is Done! \n",
      "\n",
      "2356/2356 [==============================] - 1s 358us/step\n",
      "(51261, 216): MLP Classifier is Done! \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# MLPClassifier NewFeatures\n",
    "mlp_newf = kfold_training('MLP', X_train_NewF_M_N, Y_train_NewF_M_N, mlp_model, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "12477cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_results(mlp_newf, \"MLPClassifier_NewFeatures_MN_Results\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e0a65e46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2768/2768 [==============================] - 1s 368us/step\n",
      "(73492, 216): MLP Classifier is Done! \n",
      "\n",
      "1329/1329 [==============================] - 1s 361us/step\n",
      "(88557, 216): MLP Classifier is Done! \n",
      "\n",
      "1602/1602 [==============================] - 1s 376us/step\n",
      "(42510, 216): MLP Classifier is Done! \n",
      "\n",
      "2356/2356 [==============================] - 1s 369us/step\n",
      "(51261, 216): MLP Classifier is Done! \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# MLPClassifier NewFeatures\n",
    "mlp_newf = kfold_training('MLP', X_train_NewF_Z_N, Y_train_NewF_Z_N, mlp_model, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ffb56dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_results(mlp_newf, \"MLPClassifier_NewFeatures_ZN_Results\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e702be07",
   "metadata": {},
   "source": [
    "### K Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b24408d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(73492, 216): KNeighborsClassifier Classifier is Done! \n",
      "\n",
      "(88557, 216): KNeighborsClassifier Classifier is Done! \n",
      "\n",
      "(42510, 216): KNeighborsClassifier Classifier is Done! \n",
      "\n",
      "(51261, 216): KNeighborsClassifier Classifier is Done! \n",
      "\n"
     ]
    }
   ],
   "source": [
    "naive_newf = kfold_training('KNN', X_train_NewF_LSBZM, Y_train_NewF_LSBZM, knn_model, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6ac1c1a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_results(naive_newf, \"KNN_NewFeatures_Results\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "390bc562",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(73492, 216): KNeighborsClassifier Classifier is Done! \n",
      "\n",
      "(88557, 216): KNeighborsClassifier Classifier is Done! \n",
      "\n",
      "(42510, 216): KNeighborsClassifier Classifier is Done! \n",
      "\n",
      "(51261, 216): KNeighborsClassifier Classifier is Done! \n",
      "\n"
     ]
    }
   ],
   "source": [
    "naive_newf = kfold_training('KNN', X_train_NewF_M, Y_train_NewF_M, knn_model, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6fb67301",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_results(naive_newf, \"KNN_NewFeatures_MM_Results\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d826cee0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(73492, 216): KNeighborsClassifier Classifier is Done! \n",
      "\n",
      "(88557, 216): KNeighborsClassifier Classifier is Done! \n",
      "\n",
      "(42510, 216): KNeighborsClassifier Classifier is Done! \n",
      "\n",
      "(51261, 216): KNeighborsClassifier Classifier is Done! \n",
      "\n"
     ]
    }
   ],
   "source": [
    "naive_newf = kfold_training('KNN', X_train_NewF_Z, Y_train_NewF_Z, knn_model, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "57a9976a",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_results(naive_newf, \"KNN_NewFeatures_ZM_Results\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "fad0ff95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(73492, 216): KNeighborsClassifier Classifier is Done! \n",
      "\n",
      "(88557, 216): KNeighborsClassifier Classifier is Done! \n",
      "\n",
      "(42510, 216): KNeighborsClassifier Classifier is Done! \n",
      "\n",
      "(51261, 216): KNeighborsClassifier Classifier is Done! \n",
      "\n"
     ]
    }
   ],
   "source": [
    "naive_newf = kfold_training('KNN', X_train_NewF_M_N, Y_train_NewF_M_N, knn_model, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9f5fc90b",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_results(naive_newf, \"KNN_NewFeatures_MN_Results\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a19671cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(73492, 216): KNeighborsClassifier Classifier is Done! \n",
      "\n",
      "(88557, 216): KNeighborsClassifier Classifier is Done! \n",
      "\n",
      "(42510, 216): KNeighborsClassifier Classifier is Done! \n",
      "\n",
      "(51261, 216): KNeighborsClassifier Classifier is Done! \n",
      "\n"
     ]
    }
   ],
   "source": [
    "naive_newf = kfold_training('KNN', X_train_NewF_Z_N, Y_train_NewF_Z_N, knn_model, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ceab9e8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_results(naive_newf, \"KNN_NewFeatures_ZN_Results\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c43112c",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "fc2f461e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(73492, 216): Random Forest Classifier is Done! \n",
      "\n",
      "(88557, 216): Random Forest Classifier is Done! \n",
      "\n",
      "(42510, 216): Random Forest Classifier is Done! \n",
      "\n",
      "(51261, 216): Random Forest Classifier is Done! \n",
      "\n"
     ]
    }
   ],
   "source": [
    "forest_newf = kfold_training('RandomForest', X_train_NewF_LSBZM, Y_train_NewF_LSBZM, random_forest_model, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5b25573a",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_results(forest_newf, \"RandomForest_NewFeatures_Results\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "80ab020f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(73492, 216): Random Forest Classifier is Done! \n",
      "\n",
      "(88557, 216): Random Forest Classifier is Done! \n",
      "\n",
      "(42510, 216): Random Forest Classifier is Done! \n",
      "\n",
      "(51261, 216): Random Forest Classifier is Done! \n",
      "\n"
     ]
    }
   ],
   "source": [
    "forest_newf = kfold_training('RandomForest', X_train_NewF_M, Y_train_NewF_M, random_forest_model, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "15394a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_results(forest_newf, \"RandomForest_NewFeatures_MM_Results\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3126166d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(73492, 216): Random Forest Classifier is Done! \n",
      "\n",
      "(88557, 216): Random Forest Classifier is Done! \n",
      "\n",
      "(42510, 216): Random Forest Classifier is Done! \n",
      "\n",
      "(51261, 216): Random Forest Classifier is Done! \n",
      "\n"
     ]
    }
   ],
   "source": [
    "forest_newf = kfold_training('RandomForest', X_train_NewF_Z, Y_train_NewF_Z, random_forest_model, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d2fd97d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_results(forest_newf, \"RandomForest_NewFeatures_ZM_Results\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "96a16f9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(73492, 216): Random Forest Classifier is Done! \n",
      "\n",
      "(88557, 216): Random Forest Classifier is Done! \n",
      "\n",
      "(42510, 216): Random Forest Classifier is Done! \n",
      "\n",
      "(51261, 216): Random Forest Classifier is Done! \n",
      "\n"
     ]
    }
   ],
   "source": [
    "forest_newf = kfold_training('RandomForest', X_train_NewF_M_N, Y_train_NewF_M_N, random_forest_model, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "cd6d54f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_results(forest_newf, \"RandomForest_NewFeatures_MN_Results\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "62377f19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(73492, 216): Random Forest Classifier is Done! \n",
      "\n",
      "(88557, 216): Random Forest Classifier is Done! \n",
      "\n",
      "(42510, 216): Random Forest Classifier is Done! \n",
      "\n",
      "(51261, 216): Random Forest Classifier is Done! \n",
      "\n"
     ]
    }
   ],
   "source": [
    "forest_newf = kfold_training('RandomForest', X_train_NewF_Z_N, Y_train_NewF_Z_N, random_forest_model, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "541a717f",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_results(forest_newf, \"RandomForest_NewFeatures_ZN_Results\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0fc66c6",
   "metadata": {},
   "source": [
    "# Comparison "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "3941d553",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"/Users/samskanderi/Documents/Research_Project/SWANSF/code/results/\"\n",
    "with open(data_dir + 'SVM_NewFeatures_Results' + \".pkl\", 'rb') as f:\n",
    "    svm_newf=pickle.load(f)\n",
    "with open(data_dir + 'MLPClassifier_NewFeatures_Results' + \".pkl\", 'rb') as f:\n",
    "    mlp_newf=pickle.load(f)\n",
    "with open(data_dir + 'KNN_NewFeatures_Results' + \".pkl\", 'rb') as f:\n",
    "    naive_newf=pickle.load(f)\n",
    "with open(data_dir + 'RandomForest_NewFeatures_Results' + \".pkl\", 'rb') as f:\n",
    "    forest_newf=pickle.load(f)\n",
    "\n",
    "\n",
    "\n",
    "names = ['SVM', 'MLP', 'KNN', 'RandomForest']\n",
    "values = np.array([svm_newf, mlp_newf, naive_newf, forest_newf])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "88522bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_results(names, values):\n",
    "    np.printoptions(precision=4, suppress=True)\n",
    "    for i in range(0, values.shape[1]):\n",
    "        print(\"P_Train = \"+ str(values[0,i,0]) + \" & \" + \"P_Test = \" + str(values[0,i,1]))\n",
    "        for j in range(0, values.shape[0]):\n",
    "            print(names[j] + ' :' +  ' TP={:.0f}'.format(values[j,i,2]) + ' FN={:.0f}'.format(values[j,i,3]) + ' FP={:.0f}'.format(values[j,i,4])\n",
    "                 + ' TN={:.0f}'.format(values[j,i,5]) + ' TSS={:.3f}'.format(values[j,i,6]) + ' HSS1={:.3f}'.format(values[j,i,7]) + ' HSS2={:.3f}'.format(values[j,i,8])\n",
    "                 + ' GSS={:.3f}'.format(values[j,i,9]) + ' Recall={:.3f}'.format(values[j,i,10]) + ' Precision={:.3f}'.format(values[j,i,11]))\n",
    "        print('\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "9688f338",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P_Train = 4.0 & P_Test = 5.0\n",
      "SVM : TP=27 FN=963 FP=247 TN=74128 TSS=0.024 HSS1=0.037 HSS2=0.037 GSS=23.401 Recall=0.027 Precision=0.099\n",
      "MLP : TP=356 FN=634 FP=1087 TN=73288 TSS=0.345 HSS1=0.281 HSS2=0.282 GSS=337.045 Recall=0.360 Precision=0.247\n",
      "KNN : TP=211 FN=779 FP=614 TN=73761 TSS=0.205 HSS1=0.223 HSS2=0.223 GSS=200.163 Recall=0.213 Precision=0.256\n",
      "RandomForest : TP=176 FN=814 FP=252 TN=74123 TSS=0.174 HSS1=0.242 HSS2=0.243 GSS=170.378 Recall=0.178 Precision=0.411\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "compare_results(names, values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db226f87",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7d2449b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
